{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Production runner with Historical vs Closed-Loop modes.\n",
    "\n",
    "What it does (idempotent):\n",
    "  1) Ensures ML predictions for the 6-month lookback + today's stamps → CSV cache\n",
    "  2) Ensures GP residual rows for the 6-month window → Pickle cache\n",
    "  3) Fits GP on the 6-month slice\n",
    "  4) (Per stamp) Auto-tunes per-product α by slope fidelity (rc0-injected), saves fidelity\n",
    "  5) Runs multi-knob RCOT optimizer (with tuned α), prints/saves RCOT moves, price audit\n",
    "  6) Saves curves (overrides-only α, rc0-injected) + per-geometry fidelity audit\n",
    "  7) At the end: builds a counterfactual schedule and simulates corrected yields + margin\n",
    "     (consistent end-of-run check; for online closed-loop the state is updated in-loop)\n",
    "\n",
    "Supports modes:\n",
    "  - historical: baseline behavior\n",
    "  - closed_loop: apply recommended RCOTs to a stateful copy of X and hold until next decision.\n",
    "    Keeps caches separate via a cache_tag to avoid polluting historical ones.\n",
    "\n",
    "Assumes your project provides:\n",
    "  - src.data_loading (DataPipeline) to load X_12h/Y_12h/prices_df and merged LIMS\n",
    "  - src.srto_pipeline / src.srto_components to build SRTO plant-spot pipeline\n",
    "  - src.ml_predictor.MLPredictor\n",
    "  - src.gp_residuals (GPResiduals, GPFeatureConfig, anchored_curve_at_ts, setters, PRODUCTS)\n",
    "  - src.optimizer (optimize_rcot_for_ts_multi, FuelGasConstants, PriceProvider,\n",
    "                   make_margin_fn_excel_delta, corrected_yields_for_row)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Sequence, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"X does not have valid feature names, but GaussianProcessRegressor was fitted with feature names\",\n",
    "    category=UserWarning,\n",
    "    module=\"sklearn\"\n",
    ")\n",
    "\n",
    "# ---- project imports ----\n",
    "from importlib import reload\n",
    "import src.gp_residuals as gpmod\n",
    "import src.optimizer    as opt\n",
    "\n",
    "\n",
    "# =================== CONFIG (static) ===================\n",
    "LOOKBACK_6M    = pd.Timedelta(days=180)\n",
    "MIN_TR_ROWS    = 180\n",
    "GP_JOBS        = 8\n",
    "\n",
    "START          = pd.Timestamp('2025-01-01')\n",
    "END            = pd.Timestamp('2025-05-19')\n",
    "LOOKBACK_6M    = pd.Timedelta(days=180)\n",
    "MIN_TR_ROWS    = 180                    # minimum rows required in ML rolling window\n",
    "GP_JOBS        = 8                      # GP parallel jobs\n",
    "\n",
    "OUT_DIR        = Path(\"prod_out\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PRED_CACHE_CSV = OUT_DIR / \"ml_pred_cache.csv\"          # rolling ML predictions cache\n",
    "GP_CACHE_PKL   = OUT_DIR / \"gp_train_cache.pkl\"         # GP residuals (pickle)\n",
    "OPT_REC_CSV    = OUT_DIR / \"rcot_recommendations.csv\"   # per-stamp recommendations\n",
    "CURVES_DIR     = OUT_DIR / \"curves\"                     # anchored curves + audits\n",
    "CURVES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Base OUT dir; mode-specific subdirs will be derived\n",
    "OUT_DIR_BASE   = Path(\"prod_out\")\n",
    "OUT_DIR_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# RCOT bounds (single source of truth)\n",
    "RC_BOUNDS = {\n",
    "    'LF_NAPH':     (830.0, 853.0),\n",
    "    'GF_GAS':      (860.0, 890.0),\n",
    "    'GF_HYB_NAPH': (830.0, 853.0),\n",
    "}\n",
    "\n",
    "# canonical products\n",
    "PRODS_CANON = (\"Ethylene\",\"Propylene\",\"Mixed C4\",\"RPG\",\"Hydrogen\",\"Tail Gas\")\n",
    "# canonical internal keys for corrected_yields_for_row\n",
    "PRODS_INTERNAL = ['Ethylene','Propylene','MixedC4','RPG','Ethane','Propane','Hydrogen','Tail_Gas']\n",
    "TARGET_COLS = [f'{p}_prod_t+1' for p in PRODS_INTERNAL]\n",
    "\n",
    "# =================== HELPERS ===================\n",
    "def _ts_per_day(index: pd.DatetimeIndex, day: pd.Timestamp) -> List[pd.Timestamp]:\n",
    "    d0 = pd.Timestamp(day).normalize()\n",
    "    d1 = d0 + pd.Timedelta(days=1)\n",
    "    idx = index[(index >= d0) & (index < d1)]\n",
    "    return list(idx)\n",
    "\n",
    "def _safe_merge_csv(path: Path, df_new: pd.DataFrame, key: str | list[str] = 'timestamp') -> pd.DataFrame:\n",
    "    key_cols = [key] if isinstance(key, str) else list(key)\n",
    "\n",
    "    if path.exists():\n",
    "        old = pd.read_csv(path, parse_dates=[k for k in key_cols if 'time' in k.lower()])\n",
    "        old = old.set_index(key_cols).sort_index()\n",
    "    else:\n",
    "        if len(key_cols) == 1:\n",
    "            k = key_cols[0]\n",
    "            idx = (pd.DatetimeIndex([], name=k) if 'time' in k.lower() else pd.Index([], name=k))\n",
    "            old = pd.DataFrame(index=idx)\n",
    "        else:\n",
    "            idx = pd.MultiIndex.from_arrays([[] for _ in key_cols], names=key_cols)\n",
    "            old = pd.DataFrame(index=idx)\n",
    "\n",
    "    new = df_new.copy()\n",
    "    for k in key_cols:\n",
    "        if k in new.columns and 'time' in k.lower():\n",
    "            new[k] = pd.to_datetime(new[k], errors='coerce')\n",
    "    new = new.set_index(key_cols).sort_index()\n",
    "\n",
    "    out = pd.concat([old[~old.index.isin(new.index)], new], axis=0).sort_index()\n",
    "    out_reset = out.reset_index()\n",
    "    out_reset.to_csv(path, index=False)\n",
    "    return out_reset\n",
    "\n",
    "def _safe_merge_pickle(path: Path, df_new: pd.DataFrame, min_index: pd.Timestamp | None = None) -> pd.DataFrame:\n",
    "    if path.exists():\n",
    "        old = pd.read_pickle(path)\n",
    "        old.index = pd.to_datetime(old.index)\n",
    "    else:\n",
    "        old = pd.DataFrame()\n",
    "\n",
    "    if df_new is not None and len(df_new):\n",
    "        df_new = df_new.copy()\n",
    "        df_new.index = pd.to_datetime(df_new.index)\n",
    "        out = pd.concat([old, df_new], axis=0)\n",
    "    else:\n",
    "        out = old\n",
    "\n",
    "    if min_index is not None and not out.empty:\n",
    "        out = out.loc[out.index >= pd.Timestamp(min_index)]\n",
    "\n",
    "    out = out[~out.index.duplicated(keep='last')].sort_index()\n",
    "    out.to_pickle(path)\n",
    "    return out\n",
    "\n",
    "def realized_margin_from_Y(ts: pd.Timestamp, x_row: pd.Series, Y_12h: pd.DataFrame, margin_fn) -> float:\n",
    "    ydict = {}\n",
    "    for p in PRODS_INTERNAL:\n",
    "        col = f\"{p}_prod_t+1\"\n",
    "        ydict[col] = float(Y_12h.at[ts, col]) if (ts in Y_12h.index and col in Y_12h.columns) else 0.0\n",
    "    return float(margin_fn(ts, x_row, ydict))\n",
    "\n",
    "def _geometry_label_for_row(row: pd.Series) -> str:\n",
    "    n = sum(row.get(f'Naphtha_chamber{i}', 0.0) for i in range(1,7))\n",
    "    g = sum(row.get(f'Gas Feed_chamber{i}', 0.0) for i in (4,5,6))\n",
    "    if n>0 and g>0: return 'GF_HYB_NAPH'\n",
    "    if n>0:         return 'LF_NAPH'\n",
    "    if g>0:         return 'GF_GAS'\n",
    "    return 'NONE'\n",
    "\n",
    "def _norm_geom(g: str) -> str:\n",
    "    return str(g).strip().replace(\" \",\"_\").upper()\n",
    "\n",
    "def _bounds_for_geoms() -> dict[str, tuple[float,float]]:\n",
    "    return {'LF_NAPH':(800.0,895.0), 'GF_GAS':(820.0,910.0), 'GF_HYB_NAPH':(800.0,895.0)}\n",
    "\n",
    "def _rc_grid_for(ts_row: pd.Series, geom: str, lo: float, hi: float, points: int=15) -> np.ndarray:\n",
    "    rc0 = gpmod.rc0_guess_for_geom(ts_row, geom, fallback_rc=None)\n",
    "    base = np.linspace(lo, hi, points)\n",
    "    return np.unique(np.r_[base, rc0]) if rc0 is not None else base\n",
    "\n",
    "# =================== ML CACHE ADAPTER ===================\n",
    "class MLCacheAdapter:\n",
    "    \"\"\"Adapter for cached ML predictions; provides transform() (no-op) and predict_row().\"\"\"\n",
    "    def __init__(self, pred_df: pd.DataFrame):\n",
    "        self.pred_df = pred_df\n",
    "\n",
    "    def transform(self, X_12h: pd.DataFrame, Y_12h: pd.DataFrame):\n",
    "        # not used by GP table downstream, but required by interface\n",
    "        return X_12h\n",
    "\n",
    "    def predict_row(self, row_like, **kwargs):\n",
    "        ts = getattr(row_like, 'name', None)\n",
    "        if ts is None or ts not in self.pred_df.index:\n",
    "            return {}\n",
    "        s = self.pred_df.loc[ts]\n",
    "        return {c: float(s.get(c, np.nan)) for c in self.pred_df.columns}\n",
    "\n",
    "# =================== FIDELITY (slope-only gate) ===================\n",
    "def _robust_slope_metrics(curve: pd.DataFrame, prod: str) -> tuple[float,float]:\n",
    "    if curve is None or curve.empty or len(curve) < 3:\n",
    "        return (np.nan, 0.0)\n",
    "    s = curve.get(f'{prod}_SRTO_tph'); c = curve.get(f'{prod}_CORR_tph')\n",
    "    if s is None or c is None: return (np.nan, 0.0)\n",
    "    s = s.to_numpy(float); c = c.to_numpy(float)\n",
    "    ds, dc = np.diff(s), np.diff(c)\n",
    "    ds_f = ds[np.isfinite(ds)]\n",
    "    if ds_f.size == 0: return (np.nan, 0.0)\n",
    "    eps  = 0.01*(np.nanpercentile(np.abs(ds_f),95) + 1e-12)\n",
    "    mask = np.abs(ds) >= eps\n",
    "    if mask.sum() < 3 or not np.isfinite(dc[mask]).all(): return (np.nan, float(mask.mean()))\n",
    "    return (float(np.corrcoef(ds[mask], dc[mask])[0,1]), float(mask.mean()))\n",
    "\n",
    "\n",
    "def _rcot_setter_single_knob(knob: str):\n",
    "    def _setter(row_like: pd.Series, rc: float) -> pd.Series:\n",
    "        row_like[knob] = float(rc)\n",
    "        return row_like\n",
    "    return _setter\n",
    "\n",
    "def _local_rc_grid(rc0: float, lo: float, hi: float, halfspan: float = 10.0, n: int = 9) -> np.ndarray:\n",
    "    if not np.isfinite(rc0):\n",
    "        return np.linspace(lo, hi, n)\n",
    "    a, b = max(lo, rc0 - halfspan), min(hi, rc0 + halfspan)\n",
    "    return np.unique(np.r_[np.linspace(a, b, n), rc0])\n",
    "\n",
    "def _knob_from_leg(leg: dict) -> str:\n",
    "    ch = leg['chamber']\n",
    "    if leg['feed'] == 'gas':\n",
    "        return f'RCOT_gas_chamber{ch}'\n",
    "    if ch in (1,2,3):\n",
    "        return f'RCOT_chamber{ch}'\n",
    "    return f'RCOT_naphtha_chamber{ch}'\n",
    "\n",
    "def build_knob_fidelity_gate(*, ts, row_current, gp, X_12h, merged_lims, pipeline, ml_cached,\n",
    "                             rc_bounds_map, thr_corr=0.92, min_cov=0.20,\n",
    "                             halfspan_ok=10.0, halfspan_fallback=2.0):\n",
    "    \"\"\"\n",
    "    Returns: (bounds_by_knob: dict, knob_fid_df: DataFrame)\n",
    "    Policy:\n",
    "      - PASS → trust ±halfspan_ok (clipped to geometry bounds)\n",
    "      - FAIL → try SRTO finite-difference fallback; if OK → ±halfspan_fallback; else FREEZE (rc0,rc0)\n",
    "    \"\"\"\n",
    "    comp_row = gp._comp_row_for_ts(merged_lims, ts)\n",
    "    legs = pipeline._chamber_legs_from_state(row_current, feed_thr=1.0)  # active legs only\n",
    "\n",
    "    rows, bounds_by_knob = [], {}\n",
    "    KEY = ['Ethylene','Propylene','RPG']  # key revenue drivers\n",
    "\n",
    "    for leg in legs:\n",
    "        geom = leg['geometry']  # 'LF_NAPH' | 'GF_GAS' | 'GF_HYB_NAPH'\n",
    "        knob = _knob_from_leg(leg)\n",
    "        rc0  = float(row_current.get(knob, np.nan))\n",
    "        lo, hi = rc_bounds_map.get(geom, (800.0, 895.0))\n",
    "        rc_grid = _local_rc_grid(rc0, lo, hi, halfspan=halfspan_ok, n=9)\n",
    "\n",
    "        # Local anchored curve with tuned α (already set on gp)\n",
    "        curve, _ = gpmod.anchored_curve_at_ts(\n",
    "            gp=gp, X_12h=X_12h, merged_lims=merged_lims, pipeline=pipeline, ml=ml_cached,\n",
    "            ts=ts, rcot_setter=_rcot_setter_single_knob(knob), rc_grid=rc_grid,\n",
    "            use_gp_delta=True, alpha=0.0\n",
    "        )\n",
    "\n",
    "        flags = []\n",
    "        for p in KEY:\n",
    "            sc, cov = _robust_slope_metrics(curve, p)\n",
    "            rows.append({'timestamp': ts, 'geometry': geom, 'chamber': leg['chamber'],\n",
    "                         'knob': knob, 'product': p, 'slope_corr': sc, 'sign_cov': cov})\n",
    "            flags.append((sc >= thr_corr) and (cov >= min_cov))\n",
    "\n",
    "        if all(flags):\n",
    "            # PASS → generous local trust\n",
    "            a = max(lo, rc0 - halfspan_ok); b = min(hi, rc0 + halfspan_ok)\n",
    "            bounds_by_knob[knob] = (a, b)\n",
    "            continue\n",
    "\n",
    "        # Fallback: SRTO central difference at rc0 ± 5°C\n",
    "        try:\n",
    "            dC = 5.0\n",
    "            def _spot(rc):\n",
    "                r = row_current.copy(); r[knob] = float(np.clip(rc, lo, hi))\n",
    "                spot = pipeline.predict_spot_plant(r, comp_row, feed_thr=0.1)\n",
    "                return spot['totals_tph'] if spot.get('status') == 'ok' else {}\n",
    "            y_lo = _spot(rc0 - dC); y_hi = _spot(rc0 + dC)\n",
    "            fd_ok = all(abs(y_hi.get(k,0.0) - y_lo.get(k,0.0)) > 1e-6 for k in KEY)\n",
    "        except Exception:\n",
    "            fd_ok = False\n",
    "\n",
    "        if fd_ok:\n",
    "            # allow micro moves only\n",
    "            a = max(lo, rc0 - halfspan_fallback); b = min(hi, rc0 + halfspan_fallback)\n",
    "            bounds_by_knob[knob] = (a, b)\n",
    "        else:\n",
    "            # freeze this knob\n",
    "            bounds_by_knob[knob] = (rc0, rc0)\n",
    "\n",
    "    return bounds_by_knob, pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def auto_alpha_until_pass_for_ts(\n",
    "    gp: gpmod.GPResiduals,\n",
    "    ts: pd.Timestamp,\n",
    "    row0: pd.Series,\n",
    "    X_12h: pd.DataFrame,\n",
    "    merged_lims: pd.DataFrame,\n",
    "    pipeline,\n",
    "    ml_cached,\n",
    "    thr_corr: float=0.92,\n",
    "    min_cov: float=0.20,\n",
    "    rc_points: int=15\n",
    ") -> tuple[dict, pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    geoms = []\n",
    "    n = sum(float(row0.get(f'Naphtha_chamber{i}',0.0)) for i in range(1,7))\n",
    "    g = sum(float(row0.get(f'Gas Feed_chamber{i}',0.0)) for i in (4,5,6))\n",
    "    if n > 1.0: geoms.append('LF_NAPH')\n",
    "    if g > 1.0: geoms.append('GF_GAS')\n",
    "    if n > 1.0 and g > 1.0: geoms.append('GF_HYB_NAPH')\n",
    "\n",
    "    setter_map = {'LF_NAPH':gpmod.rcot_setter_lf_naph, 'GF_GAS':gpmod.rcot_setter_gf_gas, 'GF_HYB_NAPH':gpmod.rcot_setter_hybrid}\n",
    "    rc_bounds  = _bounds_for_geoms()\n",
    "    setter_map = {g:setter_map[g] for g in geoms}; rc_bounds = {g:rc_bounds[g] for g in geoms}\n",
    "\n",
    "    overrides: dict[tuple[str,str], float] = {}\n",
    "    alpha_grid = np.r_[np.linspace(0.35, 0.0, 8), 0.0]\n",
    "\n",
    "    # First pass: find failing pairs\n",
    "    gp.set_alpha_overrides({})\n",
    "    fid_rows = []\n",
    "    for g in geoms:\n",
    "        lo, hi = rc_bounds[g]; rc_grid = _rc_grid_for(row0, g, lo, hi, points=rc_points)\n",
    "        curve, _ = gpmod.anchored_curve_at_ts(\n",
    "            gp=gp, X_12h=X_12h, merged_lims=merged_lims, pipeline=pipeline,\n",
    "            ml=ml_cached, ts=ts, rcot_setter=setter_map[g], rc_grid=rc_grid,\n",
    "            use_gp_delta=True, alpha=0.0\n",
    "        )\n",
    "        for p in gpmod.PRODUCTS:\n",
    "            sc, cov = _robust_slope_metrics(curve, p)\n",
    "            fid_rows.append({'timestamp': ts, 'geometry': _norm_geom(g), 'product': p, 'slope_corr': sc, 'sign_cov': cov})\n",
    "    fid0 = pd.DataFrame(fid_rows)\n",
    "    fails = fid0.loc[(fid0['slope_corr'] < thr_corr) | (fid0['sign_cov'] < min_cov), ['product','geometry']].drop_duplicates()\n",
    "\n",
    "    # Iterate α for failing pairs\n",
    "    for prod, geom in fails.itertuples(index=False):\n",
    "        tcol = gpmod.TARGET_MAP[prod]\n",
    "        best = None\n",
    "        for a in alpha_grid:\n",
    "            trial = {**overrides, (_norm_geom(geom), tcol): float(a)}\n",
    "            gp.set_alpha_overrides(trial)\n",
    "            lo, hi = rc_bounds[geom]; rc_grid = _rc_grid_for(row0, geom, lo, hi, points=rc_points)\n",
    "            curve, _ = gpmod.anchored_curve_at_ts(\n",
    "                gp=gp, X_12h=X_12h, merged_lims=merged_lims, pipeline=pipeline,\n",
    "                ml=ml_cached, ts=ts, rcot_setter=setter_map[geom], rc_grid=rc_grid,\n",
    "                use_gp_delta=True, alpha=0.0\n",
    "            )\n",
    "            sc, cov = _robust_slope_metrics(curve, prod)\n",
    "            if sc >= thr_corr and cov >= min_cov:\n",
    "                best = float(a); break\n",
    "        overrides[(_norm_geom(geom), tcol)] = (0.0 if best is None else best)\n",
    "\n",
    "    # Final detail/summary with overrides\n",
    "    gp.set_alpha_overrides(overrides)\n",
    "    fid_rows = []\n",
    "    for g in geoms:\n",
    "        lo, hi = rc_bounds[g]; rc_grid = _rc_grid_for(row0, g, lo, hi, points=rc_points)\n",
    "        curve, _ = gpmod.anchored_curve_at_ts(\n",
    "            gp=gp, X_12h=X_12h, merged_lims=merged_lims, pipeline=pipeline,\n",
    "            ml=ml_cached, ts=ts, rcot_setter=setter_map[g], rc_grid=rc_grid,\n",
    "            use_gp_delta=True, alpha=0.0\n",
    "        )\n",
    "        for p in gpmod.PRODUCTS:\n",
    "            sc, cov = _robust_slope_metrics(curve, p)\n",
    "            a_col, c_col = f'{p}_ANCHOR_tph', f'{p}_CORR_tph'\n",
    "            diff = (curve[c_col].astype(float) - curve[a_col].astype(float)).abs().to_numpy(float) if (a_col in curve and c_col in curve) else np.array([np.nan])\n",
    "            am_min = float(np.nanmin(diff))\n",
    "            fid_rows.append({'timestamp': ts, 'geometry': _norm_geom(g), 'product': p,\n",
    "                             'slope_corr': sc, 'sign_cov': cov, 'anchor_miss_min': am_min})\n",
    "    fid = pd.DataFrame(fid_rows)\n",
    "    fid['slope_ok'] = (fid['slope_corr'] >= thr_corr) & (fid['sign_cov'] >= min_cov)\n",
    "    summ = (fid.groupby(['product','geometry'])['slope_ok']\n",
    "                .agg(pct_ok=lambda s: float(100.0*s.mean()), n='count')\n",
    "                .reset_index()\n",
    "                .sort_values(['product','geometry']))\n",
    "    return overrides, fid, summ\n",
    "\n",
    "# =================== Counterfactual schedule & simulate ===================\n",
    "def build_rcot_schedule_from_recs(rec_df: pd.DataFrame) -> list[tuple[pd.Timestamp, dict]]:\n",
    "    if 'timestamp' in rec_df.columns:\n",
    "        df = rec_df.set_index('timestamp')\n",
    "    else:\n",
    "        df = rec_df.copy()\n",
    "    df = df.sort_index()\n",
    "    knobs_cols = [c for c in df.columns if c.startswith('rcot_opt_')]\n",
    "    sched = []\n",
    "    for ts, r in df.iterrows():\n",
    "        setpoints = {}\n",
    "        for c in knobs_cols:\n",
    "            v = r.get(c, np.nan)\n",
    "            if pd.notna(v):\n",
    "                knob = c.replace('rcot_opt_', '')\n",
    "                setpoints[knob] = float(v)\n",
    "        if setpoints:\n",
    "            sched.append((pd.Timestamp(ts), setpoints))\n",
    "    return sched\n",
    "\n",
    "def apply_schedule_to_X(X_12h: pd.DataFrame, schedule: list[tuple[pd.Timestamp, dict]],\n",
    "                        start: pd.Timestamp | None = None,\n",
    "                        end:   pd.Timestamp | None = None,\n",
    "                        hold: str = \"hold_until_next\") -> pd.DataFrame:\n",
    "    X_sim = X_12h.copy(); idx = X_sim.index\n",
    "    if start is None: start = idx.min()\n",
    "    if end   is None: end   = idx.max()\n",
    "    schedule = sorted([(pd.Timestamp(t), d) for (t,d) in schedule if start <= pd.Timestamp(t) <= end],\n",
    "                      key=lambda x: x[0])\n",
    "    if not schedule:\n",
    "        return X_sim\n",
    "    schedule2 = schedule + [(pd.Timestamp(end) + pd.Timedelta(seconds=1), {})]\n",
    "    for (t0, setpoints), (t1, _) in zip(schedule2[:-1], schedule2[1:]):\n",
    "        mask = (idx >= t0) & (idx < t1)\n",
    "        if not mask.any(): continue\n",
    "        for knob, val in setpoints.items():\n",
    "            if knob in X_sim.columns:\n",
    "                X_sim.loc[mask, knob] = float(val)\n",
    "    return X_sim\n",
    "\n",
    "def simulate_path_corrected(X_sim: pd.DataFrame,\n",
    "                            merged_lims: pd.DataFrame,\n",
    "                            pipeline,\n",
    "                            gp: gpmod.GPResiduals,\n",
    "                            gps_dict: dict,\n",
    "                            feature_cols_gp: list[str],\n",
    "                            price_provider: opt.PriceProvider,\n",
    "                            total_spyro_yield_for_now,\n",
    "                            fg_consts: opt.FuelGasConstants,\n",
    "                            alpha_overrides: dict | None = None,\n",
    "                            start: pd.Timestamp | None = None,\n",
    "                            end:   pd.Timestamp | None = None) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    idx = X_sim.index\n",
    "    if start is None: start = idx.min()\n",
    "    if end   is None: end   = idx.max()\n",
    "    stamps = idx[(idx >= start) & (idx <= end)]\n",
    "\n",
    "    margin_fn = opt.make_margin_fn_excel_delta(price_provider=price_provider,\n",
    "                                               total_spyro_yield_for_now=total_spyro_yield_for_now,\n",
    "                                               spyro_ctx=None, fg_constants=fg_consts)\n",
    "\n",
    "    Y_rows, M_rows = [], []\n",
    "    for ts in stamps:\n",
    "        row = X_sim.loc[ts].copy(); row.name = ts\n",
    "        y   = opt.corrected_yields_for_row(row, gps_dict, feature_cols_gp,\n",
    "                                           total_spyro_yield_for_now, spyro_ctx=None,\n",
    "                                           alpha_overrides=alpha_overrides)\n",
    "        Y_rows.append({'timestamp': ts, **y})\n",
    "        M_rows.append({'timestamp': ts, 'margin_per_h': float(margin_fn(ts, row, y))})\n",
    "\n",
    "    Y_sim = pd.DataFrame(Y_rows).set_index('timestamp').sort_index()\n",
    "    M_sim = pd.DataFrame(M_rows).set_index('timestamp').sort_index()\n",
    "    return Y_sim, M_sim\n",
    "\n",
    "# def _cache_path(prefix: str, cache_tag: str, mode: str, train_mode: str, ext: str) -> Path:\n",
    "#     tag = cache_tag or \"\"\n",
    "#     return OUTDIR / f\"{prefix}{tag}_{mode}_{train_mode}.{ext}\"\n",
    "\n",
    "def effective_target_cols(Y_12h: pd.DataFrame, explicit: Optional[Sequence[str]] = None) -> List[str]:\n",
    "    \"\"\"Union of explicit target list and anything in Y_12h that looks like a t+1 product.\"\"\"\n",
    "    from_cols = [c for c in Y_12h.columns if c.endswith(\"_prod_t+1\")]\n",
    "    if explicit is None:\n",
    "        return sorted(set(from_cols))\n",
    "    return sorted(set(explicit) | set(from_cols))\n",
    "\n",
    "def seed_sim_state(Y_12h: pd.DataFrame, tcols: Sequence[str], seed_until: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a closed-loop Y-state with *full* target coverage.\n",
    "    Pre-fill historical part (<= seed_until) from real Y_12h, future as NaN.\n",
    "    \"\"\"\n",
    "    ys = pd.DataFrame(index=Y_12h.index, columns=list(tcols), dtype=float)\n",
    "    common = [c for c in tcols if c in Y_12h.columns]\n",
    "    ys.loc[:, common] = Y_12h[common]\n",
    "    ys.loc[ys.index > seed_until, :] = np.nan\n",
    "    return ys\n",
    "\n",
    "def ensure_ml_preds_for(\n",
    "    stamps: Sequence[pd.Timestamp],\n",
    "    Xsrc: pd.DataFrame,\n",
    "    Ysrc: pd.DataFrame,\n",
    "    lookback: pd.Timedelta,\n",
    "    target_cols: Sequence[str],\n",
    "    *,\n",
    "    mode: str,                 # 'historical' | 'closed_loop'\n",
    "    train_mode: str,           # 'historical' | 'simulated'\n",
    "    cache_tag: str = \"\",\n",
    "    Y_sim_state: Optional[pd.DataFrame] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predict ML targets for `stamps`, keeping a cache per (mode, train_mode, cache_tag).\n",
    "    - train_mode=historical  → fit on Ysrc (ground truth)\n",
    "    - train_mode=simulated   → fit on Y_sim_state (simulated truth)\n",
    "    - Lags always read from (Y_sim_state ⊕ Ysrc) during closed-loop to avoid KeyErrors.\n",
    "    \"\"\"\n",
    "    cache_csv = _cache_path(\"ml_cache\", cache_tag, mode, train_mode, \"csv\")\n",
    "    if cache_csv.exists():\n",
    "        pred_cache = pd.read_csv(cache_csv, parse_dates=[\"timestamp\"]).set_index(\"timestamp\")\n",
    "    else:\n",
    "        pred_cache = pd.DataFrame(index=pd.DatetimeIndex([], name=\"timestamp\"))\n",
    "\n",
    "    missing = sorted(ts for ts in stamps if ts not in pred_cache.index)\n",
    "\n",
    "    if not missing:\n",
    "        # already cached\n",
    "        return pred_cache\n",
    "\n",
    "    rows = []\n",
    "    tcols = list(target_cols)\n",
    "\n",
    "    for ts in missing:\n",
    "        ts_start = ts - lookback\n",
    "        tr = Xsrc.index[(Xsrc.index >= ts_start) & (Xsrc.index < ts)]\n",
    "        if len(tr) < 10:\n",
    "            # too few samples; skip or fill NaNs\n",
    "            rows.append({\"timestamp\": ts, **{c: np.nan for c in tcols}})\n",
    "            continue\n",
    "\n",
    "        # choose training Y\n",
    "        if train_mode == \"simulated\" and Y_sim_state is not None:\n",
    "            Y_train = Y_sim_state\n",
    "        else:\n",
    "            Y_train = Ysrc\n",
    "\n",
    "        ml = MLPredictor(\n",
    "            target_cols=tcols,\n",
    "            cfg=MLPredictorConfig(\n",
    "                ds_prefixes=[\"DS_chamber\"],\n",
    "                add_virtual_rcots=True,\n",
    "                build_lag1_from_targets=True,\n",
    "                lgbm_params=dict(verbosity=-1, n_jobs=2),\n",
    "            ),\n",
    "        ).fit(Xsrc.loc[tr], Y_train.loc[tr])\n",
    "\n",
    "        # choose lag source (combine so missing columns are tolerated)\n",
    "        if mode == \"closed_loop\" and Y_sim_state is not None:\n",
    "            Y_lag_src = Y_sim_state.combine_first(Ysrc)\n",
    "        else:\n",
    "            Y_lag_src = Ysrc\n",
    "\n",
    "        pm = ml.predict_row(Xsrc.loc[ts], Y_for_lags=Y_lag_src)\n",
    "\n",
    "        rows.append({\"timestamp\": ts, **{c: float(pm.get(c, np.nan)) for c in tcols}})\n",
    "\n",
    "    if rows:\n",
    "        add_df = pd.DataFrame(rows).set_index(\"timestamp\")\n",
    "        pred_cache = pd.concat([pred_cache, add_df], axis=0).sort_index()\n",
    "        pred_cache.to_csv(cache_csv, index=True)\n",
    "\n",
    "    return pred_cache\n",
    "\n",
    "\n",
    "def _legs_to_df(legs: list[dict]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    keep = ['Ethylene','Propylene','MixedC4','RPG','PFO','Ethane','Propane','Tail_Gas','Hydrogen']\n",
    "    for lg in legs:\n",
    "        rec = {\n",
    "            'chamber': lg.get('chamber'),\n",
    "            'feed': lg.get('feed'),\n",
    "            'geometry': lg.get('geometry'),\n",
    "            'rcot_used': float(lg.get('rcot_used', np.nan)),\n",
    "            'feed_tph': float(lg.get('feed_tph', 0.0)),\n",
    "            'IRET': float(lg.get('IRET', np.nan))\n",
    "        }\n",
    "        for k in keep:\n",
    "            rec[f'{k}_tph'] = float(lg.get('tph', {}).get(k, 0.0))\n",
    "        rows.append(rec)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def ensure_ml_preds_for(\n",
    "    stamps: Sequence[pd.Timestamp],\n",
    "    Xsrc: pd.DataFrame,\n",
    "    Ysrc: pd.DataFrame,\n",
    "    lookback: pd.Timedelta,\n",
    "    target_cols: Sequence[str],\n",
    "    *,\n",
    "    mode: str,                 # 'historical' | 'closed_loop'\n",
    "    train_mode: str,           # 'historical' | 'simulated'\n",
    "    cache_tag: str = \"\",\n",
    "    Y_sim_state: Optional[pd.DataFrame] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predict ML targets for `stamps`, keeping a cache per (mode, train_mode, cache_tag).\n",
    "    - train_mode=historical  → fit on Ysrc (ground truth)\n",
    "    - train_mode=simulated   → fit on Y_sim_state (simulated truth)\n",
    "    - Lags always read from (Y_sim_state ⊕ Ysrc) during closed-loop to avoid KeyErrors.\n",
    "    \"\"\"\n",
    "    cache_csv = _cache_path(\"ml_cache\", cache_tag, mode, train_mode, \"csv\")\n",
    "    if cache_csv.exists():\n",
    "        pred_cache = pd.read_csv(cache_csv, parse_dates=[\"timestamp\"]).set_index(\"timestamp\")\n",
    "    else:\n",
    "        pred_cache = pd.DataFrame(index=pd.DatetimeIndex([], name=\"timestamp\"))\n",
    "\n",
    "    missing = sorted(ts for ts in stamps if ts not in pred_cache.index)\n",
    "\n",
    "    if not missing:\n",
    "        # already cached\n",
    "        return pred_cache\n",
    "\n",
    "    rows = []\n",
    "    tcols = list(target_cols)\n",
    "\n",
    "    for ts in missing:\n",
    "        ts_start = ts - lookback\n",
    "        tr = Xsrc.index[(Xsrc.index >= ts_start) & (Xsrc.index < ts)]\n",
    "        if len(tr) < 10:\n",
    "            # too few samples; skip or fill NaNs\n",
    "            rows.append({\"timestamp\": ts, **{c: np.nan for c in tcols}})\n",
    "            continue\n",
    "\n",
    "        # choose training Y\n",
    "        if train_mode == \"simulated\" and Y_sim_state is not None:\n",
    "            Y_train = Y_sim_state\n",
    "        else:\n",
    "            Y_train = Ysrc\n",
    "\n",
    "        ml = MLPredictor(\n",
    "            target_cols=tcols,\n",
    "            cfg=MLPredictorConfig(\n",
    "                ds_prefixes=[\"DS_chamber\"],\n",
    "                add_virtual_rcots=True,\n",
    "                build_lag1_from_targets=True,\n",
    "                lgbm_params=dict(verbosity=-1, n_jobs=2),\n",
    "            ),\n",
    "        ).fit(Xsrc.loc[tr], Y_train.loc[tr])\n",
    "\n",
    "        # choose lag source (combine so missing columns are tolerated)\n",
    "        if mode == \"closed_loop\" and Y_sim_state is not None:\n",
    "            Y_lag_src = Y_sim_state.combine_first(Ysrc)\n",
    "        else:\n",
    "            Y_lag_src = Ysrc\n",
    "\n",
    "        pm = ml.predict_row(Xsrc.loc[ts], Y_for_lags=Y_lag_src)\n",
    "\n",
    "        rows.append({\"timestamp\": ts, **{c: float(pm.get(c, np.nan)) for c in tcols}})\n",
    "\n",
    "    if rows:\n",
    "        add_df = pd.DataFrame(rows).set_index(\"timestamp\")\n",
    "        pred_cache = pd.concat([pred_cache, add_df], axis=0).sort_index()\n",
    "        pred_cache.to_csv(cache_csv, index=True)\n",
    "\n",
    "    return pred_cache\n",
    "def _ch_from_knob(knob: str) -> int | None:\n",
    "    if knob.startswith('RCOT_chamber'):            return int(knob.replace('RCOT_chamber',''))\n",
    "    if knob.startswith('RCOT_naphtha_chamber'):    return int(knob.replace('RCOT_naphtha_chamber',''))\n",
    "    if knob.startswith('RCOT_gas_chamber'):        return int(knob.replace('RCOT_gas_chamber',''))\n",
    "    return None\n",
    "\n",
    "\n",
    "# =================== RUNNER ===================\n",
    "def run_production(X_12h: pd.DataFrame, Y_12h: pd.DataFrame,\n",
    "                   merged_lims: pd.DataFrame, pipeline,\n",
    "                   prices_df: pd.DataFrame,\n",
    "                   total_spyro_yield_for_now,\n",
    "                   start: pd.Timestamp,\n",
    "                   end:   pd.Timestamp | None = None,\n",
    "                   mode: str = 'historical',\n",
    "                   closed_loop_opts: dict | None = None):\n",
    "    \"\"\"\n",
    "    mode:\n",
    "      - 'historical': baseline behavior\n",
    "      - 'closed_loop': step & hold recommended RCOTs on a stateful copy of X;\n",
    "                       uses simulated lags for ML/inference; separate caches via cache_tag.\n",
    "    closed_loop_opts:\n",
    "      dict(\n",
    "        apply_timing='next_day'|'next_stamp',\n",
    "        hold_policy='hold_until_next'|'point_only',   # currently only 'hold_until_next' honored\n",
    "        ml_train_mode='historical'|'simulated',       # training data provenance\n",
    "        gp_train_mode='historical'|'simulated',\n",
    "        cache_tag='_sim'\n",
    "      )\n",
    "    \"\"\"\n",
    "    assert mode in ('historical','closed_loop')\n",
    "    closed_loop_opts = closed_loop_opts or {}\n",
    "    apply_timing  = closed_loop_opts.get('apply_timing', 'next_day')\n",
    "    hold_policy   = closed_loop_opts.get('hold_policy',  'hold_until_next')\n",
    "    ml_train_mode = closed_loop_opts.get('ml_train_mode','historical')\n",
    "    gp_train_mode = closed_loop_opts.get('gp_train_mode','historical')\n",
    "    cache_tag     = closed_loop_opts.get('cache_tag',    '' if mode=='historical' else '_sim')\n",
    "\n",
    "    # Out dirs & caches\n",
    "    OUT_DIR = OUT_DIR_BASE / (('closed_loop' + cache_tag) if mode=='closed_loop' else 'historical')\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    CURVES_DIR = OUT_DIR / \"curves\"; CURVES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    FID_DIR    = OUT_DIR / \"fidelity\"; FID_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    MOV_DIR    = OUT_DIR / \"rcot_moves\"; MOV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    AK_DIR     = OUT_DIR / \"active_knobs\"; AK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    AUD_DIR    = OUT_DIR / \"audits\"; AUD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    SNAP_DIR   = OUT_DIR / \"multi_snapshots\"; SNAP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    CF_DIR     = OUT_DIR / \"counterfactual\"; CF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    KNOB_FID_DIR = FID_DIR / \"knob\"; KNOB_FID_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    ATTR_DIR = OUT_DIR / \"attribution\"; ATTR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    PRED_CACHE_CSV = OUT_DIR / f\"ml_pred_cache{cache_tag}.csv\"\n",
    "    GP_CACHE_PKL   = OUT_DIR / f\"gp_train_cache{cache_tag}.pkl\"\n",
    "    OPT_REC_CSV    = OUT_DIR / f\"rcot_recommendations{cache_tag}.csv\"\n",
    "\n",
    "    pp = opt.PriceProvider(prices_df)\n",
    "    gpmod.set_rcot_groups_from_columns(X_12h.columns)\n",
    "\n",
    "    # fuel-gas constants\n",
    "    fg_consts = opt.FuelGasConstants(\n",
    "        rc_ref_naph=840.0, rc_ref_gas=880.0,\n",
    "        cp_wavg_kcal_per_ton_K=411.488209,\n",
    "        dH_eth_kcal_per_ton=1_080_970.0,\n",
    "        dH_prop_kcal_per_ton=673_409.0,\n",
    "        dH_fg_kcal_per_ton=926_147.0,\n",
    "        fuel_gas_heat_content_kcal_per_ton=15_294_088.0\n",
    "    )\n",
    "\n",
    "    idx_all = X_12h.index.sort_values()\n",
    "    if end is None: end = idx_all.max().normalize()\n",
    "    days = pd.date_range(pd.Timestamp(start).normalize(), pd.Timestamp(end).normalize(), freq='D')\n",
    "\n",
    "    # Closed-loop state\n",
    "    X_state = X_12h.copy()\n",
    "    # Y_sim_state = pd.DataFrame(index=X_12h.index, columns=TARGET_COLS, dtype=float) if mode=='closed_loop' else None\n",
    "    # AFTER (seed with real history; overwrite as we simulate)\n",
    "    tcols_for_sim = [c for c in TARGET_COLS if c in Y_12h.columns]\n",
    "    if mode == 'closed_loop':\n",
    "        # start with the real Y; this guarantees non-empty training slices\n",
    "        Y_sim_state = Y_12h.reindex(columns=tcols_for_sim).copy()\n",
    "    else:\n",
    "        Y_sim_state = None\n",
    "\n",
    "\n",
    "    rcot_schedule = []  # accumulate setpoints as we go (for audit or re-apply)\n",
    "\n",
    "    # # --------- local cache helpers with tag ---------\n",
    "    def ensure_ml_preds_for(ts_list, Xs, Ys, lookback=LOOKBACK_6M, target_cols=None):\n",
    "        tcols = list(target_cols) if target_cols is not None else [c for c in TARGET_COLS if c in Ys.columns]\n",
    "        if PRED_CACHE_CSV.exists():\n",
    "            pred = pd.read_csv(PRED_CACHE_CSV, parse_dates=['timestamp']).set_index('timestamp')\n",
    "            for c in tcols:\n",
    "                if c not in pred.columns: pred[c] = np.nan\n",
    "        else:\n",
    "            pred = pd.DataFrame(index=pd.DatetimeIndex([], name='timestamp'), columns=tcols)\n",
    "        idx_full = Xs.index.sort_values()\n",
    "        ts_list = sorted(set(ts_list))\n",
    "        missing_rows = [ts for ts in ts_list if ts not in pred.index]\n",
    "        present = [ts for ts in ts_list if ts in pred.index]\n",
    "        need_backfill = []\n",
    "        if present:\n",
    "            na_mask = pred.loc[present, tcols].isna().any(axis=1)\n",
    "            need_backfill = list(pd.Index(present)[na_mask])\n",
    "        to_compute = sorted(set(missing_rows + need_backfill))\n",
    "        if not to_compute:\n",
    "            return pred\n",
    "        # If ml_train_mode == 'simulated', use X_state & (Y_sim_state if available)\n",
    "        Xsrc = (X_state if (mode=='closed_loop' and ml_train_mode=='simulated') else Xs)\n",
    "        Ysrc = (Y_sim_state if (mode=='closed_loop' and Y_sim_state is not None and ml_train_mode=='simulated') else Ys)\n",
    "\n",
    "        cfg_ml = MLPredictorConfig = None  # lazy import when used\n",
    "        if 'src.ml_predictor' in globals():\n",
    "            pass\n",
    "        try:\n",
    "            from src.ml_predictor import MLPredictor, MLPredictorConfig\n",
    "        except Exception:\n",
    "            MLPredictor = None\n",
    "        if MLPredictor is None:\n",
    "            raise RuntimeError(\"src.ml_predictor.MLPredictor not available.\")\n",
    "        rows = []\n",
    "        for ts in to_compute:\n",
    "            tr = (Xsrc.index >= ts - lookback) & (Xsrc.index < ts)\n",
    "            if tr.sum() < MIN_TR_ROWS:\n",
    "                continue\n",
    "            ml = MLPredictor(target_cols=tcols, cfg=MLPredictorConfig(\n",
    "                ds_prefixes=['DS_chamber'],\n",
    "                add_virtual_rcots=True,\n",
    "                build_lag1_from_targets=True,\n",
    "                lgbm_params=dict(verbosity=-1, n_jobs=2)\n",
    "            )).fit(Xsrc.loc[tr], Ysrc.loc[tr])\n",
    "            # pm = ml.predict_row(Xsrc.loc[ts], Y_for_lags=(Y_sim_state if (mode=='closed_loop' and Y_sim_state is not None) else Ys))\n",
    "            # Prediction source — always the updated state & simulated lags in closed_loop\n",
    "            X_pred = (X_state if mode == 'closed_loop' else Xs)\n",
    "            Y_lags = (Y_sim_state if (mode == 'closed_loop' and Y_sim_state is not None) else Ys)\n",
    "\n",
    "            pm = ml.predict_row(X_pred.loc[ts], Y_for_lags=Y_lags)\n",
    "\n",
    "\n",
    "            rows.append({'timestamp': ts, **{c: float(pm.get(c, np.nan)) for c in tcols}})\n",
    "        if rows:\n",
    "            df_new = pd.DataFrame(rows)\n",
    "            pred = _safe_merge_csv(PRED_CACHE_CSV, df_new, key='timestamp').set_index('timestamp')\n",
    "        return pred\n",
    "\n",
    "    def ensure_gp_train_for_window(train_start: pd.Timestamp, train_end: pd.Timestamp,\n",
    "                                   Xs: pd.DataFrame, Ys: pd.DataFrame,\n",
    "                                   merged_lims: pd.DataFrame, pipeline,\n",
    "                                   ml_cached: MLCacheAdapter) -> pd.DataFrame:\n",
    "        \"\"\"Keep GP training cache; optionally use simulated state in closed_loop if gp_train_mode=='simulated'.\"\"\"\n",
    "        if GP_CACHE_PKL.exists():\n",
    "            gp_cache = pd.read_pickle(GP_CACHE_PKL)\n",
    "            gp_cache.index = pd.to_datetime(gp_cache.index)\n",
    "            cached_idx = gp_cache.index\n",
    "        else:\n",
    "            gp_cache = pd.DataFrame(); cached_idx = pd.DatetimeIndex([])\n",
    "\n",
    "        idx_in_win = Xs.index[(Xs.index >= train_start) & (Xs.index <= train_end)]\n",
    "        need = [ts for ts in idx_in_win if ts not in cached_idx]\n",
    "        if need:\n",
    "            s = min(need); e = max(need)\n",
    "            Xsrc = (X_state if (mode=='closed_loop' and gp_train_mode=='simulated') else Xs)\n",
    "            Ysrc = (Y_sim_state if (mode=='closed_loop' and Y_sim_state is not None and gp_train_mode=='simulated') else Ys)\n",
    "            df_new = gpmod.GPResiduals.build_training_table(\n",
    "                Xsrc, Ysrc, merged_lims, pipeline,\n",
    "                start=s, end=e, feed_thr=0.1,\n",
    "                feature_cfg=gpmod.GPFeatureConfig(\n",
    "                    ds_prefixes=['DS_chamber'], rcot_prefixes=['RCOT_'],\n",
    "                    feed_prefixes=['Naphtha_chamber','Gas Feed_chamber'],\n",
    "                    include_ratio_naphtha=True, include_geometry_flags=True\n",
    "                ),\n",
    "                residual_kind='ml', ml=ml_cached\n",
    "            )\n",
    "            if not df_new.empty:\n",
    "                df_new.index = pd.to_datetime(df_new.index)\n",
    "                _safe_merge_pickle(GP_CACHE_PKL, df_new, min_index=train_start)\n",
    "        if GP_CACHE_PKL.exists():\n",
    "            win = pd.read_pickle(GP_CACHE_PKL)\n",
    "            win.index = pd.to_datetime(win.index)\n",
    "            win = win.loc[(win.index >= train_start) & (win.index <= train_end)].sort_index()\n",
    "        else:\n",
    "            win = pd.DataFrame()\n",
    "        return win\n",
    "\n",
    "    # ===== daily loop =====\n",
    "    idx_all = X_12h.index.sort_values()\n",
    "    for day in pd.date_range(pd.Timestamp(start).normalize(), pd.Timestamp(end).normalize(), freq='D'):\n",
    "        stamps = _ts_per_day(idx_all, day)\n",
    "        if not stamps:\n",
    "            continue\n",
    "        te = stamps[-1] - pd.Timedelta(hours=12)\n",
    "        ts_train_start = te - LOOKBACK_6M\n",
    "\n",
    "        # ML cache (respect training mode)\n",
    "        needed_for_ml = list(X_12h.index[(X_12h.index >= ts_train_start) & (X_12h.index <= te)]) + stamps\n",
    "        # tcols_ml = [c for c in Y_12h.columns if c.endswith('_prod_t+1')]\n",
    "        tcols_ml = [c for c in TARGET_COLS if c in Y_12h.columns]\n",
    "\n",
    "        pred_cache = ensure_ml_preds_for(sorted(set(needed_for_ml)),\n",
    "                                         X_12h, Y_12h, lookback=LOOKBACK_6M,\n",
    "                                         target_cols=tcols_ml)\n",
    "        ml_cached = MLCacheAdapter(pred_cache)\n",
    "\n",
    "        # GP train cache\n",
    "        df_train_win = ensure_gp_train_for_window(ts_train_start, te, X_12h, Y_12h, merged_lims, pipeline, ml_cached)\n",
    "        if df_train_win.empty:\n",
    "            continue\n",
    "\n",
    "        gp = gpmod.GPResiduals(\n",
    "            feature_cfg=gpmod.GPFeatureConfig(\n",
    "                ds_prefixes=['DS_chamber'], rcot_prefixes=['RCOT_'],\n",
    "                feed_prefixes=['Naphtha_chamber','Gas Feed_chamber'],\n",
    "                include_ratio_naphtha=True, include_geometry_flags=True\n",
    "            ),\n",
    "            n_restarts=2, normalize_y=True\n",
    "        ).fit_parallel(df_train_win, n_jobs=GP_JOBS)\n",
    "\n",
    "        gps_dict = {f'{p}_prod_t+1': gp.models_[p] for p in gpmod.PRODUCTS if p in gp.models_}\n",
    "        feature_cols_gp = gp.feature_names_\n",
    "\n",
    "        rec_rows = []\n",
    "        for ts in stamps:\n",
    "            # use X_state in closed_loop, else X_12h\n",
    "            row_current = (X_state if mode=='closed_loop' else X_12h).loc[ts].copy(); row_current.name = ts\n",
    "            # Ensure every Spyro call sees a timestamp; otherwise it returns 0\n",
    "            def _spyro_ts(row_like, short_key, ctx=None, _ts=ts):\n",
    "                r = row_like\n",
    "                if getattr(r, 'name', None) is None:\n",
    "                    r = r.copy()\n",
    "                    r.name = _ts\n",
    "                return total_spyro_yield_for_now(r, short_key, ctx)\n",
    "\n",
    "\n",
    "            geom = _geometry_label_for_row(row_current)\n",
    "            naph_b, gas_b = RC_BOUNDS.get('LF_NAPH'), RC_BOUNDS.get('GF_GAS')\n",
    "\n",
    "            # margin_fn = opt.make_margin_fn_excel_delta(\n",
    "            #     price_provider=pp,\n",
    "            #     total_spyro_yield_for_now=total_spyro_yield_for_now, spyro_ctx=None,\n",
    "            #     fg_constants=fg_consts\n",
    "            # )\n",
    "\n",
    "            margin_fn = opt.make_margin_fn_excel_delta(\n",
    "                price_provider=pp,\n",
    "                total_spyro_yield_for_now=_spyro_ts,   # ← use wrapper\n",
    "                spyro_ctx=None,\n",
    "                fg_constants=fg_consts\n",
    "            )\n",
    "\n",
    "\n",
    "            # baseline corrected yields at current RCOTs (tuned α after fidelity)\n",
    "            # First compute with α=None (pre-fidelity) for print; then with overrides after fidelity\n",
    "            # y0 = opt.corrected_yields_for_row(row_current, gps_dict, feature_cols_gp,\n",
    "            #                                   total_spyro_yield_for_now, spyro_ctx=None, alpha_overrides=None)\n",
    "\n",
    "            # y0 = opt.corrected_yields_for_row(row_current, gps_dict, feature_cols_gp,\n",
    "            #                                 total_spyro_yield_for_now, spyro_ctx=None, alpha_overrides=overrides)\n",
    "\n",
    "            # Baseline = ML at current RCOTs (spot)\n",
    "            y0 = (ml_cached.predict_row(row_current)  # keys are *_prod_t+1\n",
    "                if hasattr(ml_cached, 'predict_row') else {})\n",
    "\n",
    "\n",
    "\n",
    "            m0 = margin_fn(ts, row_current, y0)\n",
    "            m_real = realized_margin_from_Y(ts, row_current, Y_12h, margin_fn)\n",
    "\n",
    "            # fidelity & α\n",
    "            overrides, fid_detail, fid_summary = auto_alpha_until_pass_for_ts(\n",
    "                gp=gp, ts=ts, row0=row_current, X_12h=X_12h,\n",
    "                merged_lims=merged_lims, pipeline=pipeline, ml_cached=ml_cached,\n",
    "                thr_corr=0.92, min_cov=0.20, rc_points=15\n",
    "            )\n",
    "            fid_detail.to_csv(FID_DIR / f\"fidelity_detail_{ts:%Y%m%d_%H%M}.csv\", index=False)\n",
    "            fid_summary.to_csv(FID_DIR / f\"fidelity_summary_{ts:%Y%m%d_%H%M}.csv\", index=False)\n",
    "\n",
    "            bounds_by_knob, knob_fid = build_knob_fidelity_gate(\n",
    "                ts=ts, row_current=row_current, gp=gp,\n",
    "                X_12h=X_12h, merged_lims=merged_lims, pipeline=pipeline, ml_cached=ml_cached,\n",
    "                rc_bounds_map=RC_BOUNDS, thr_corr=0.92, min_cov=0.20,\n",
    "                halfspan_ok=10.0, halfspan_fallback=2.0\n",
    "            )\n",
    "            knob_fid.to_csv(KNOB_FID_DIR / f\"fidelity_knob_{ts:%Y%m%d_%H%M}.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # recompute baseline with tuned α (consistency)\n",
    "            # y0 = opt.corrected_yields_for_row(row_current, gps_dict, feature_cols_gp,\n",
    "            #                                   total_spyro_yield_for_now, spyro_ctx=None, alpha_overrides=overrides)\n",
    "\n",
    "            # y0 = opt.corrected_yields_for_row(row_current, gps_dict, feature_cols_gp,\n",
    "            #                                 _spyro_ts, spyro_ctx=None, alpha_overrides=overrides)\n",
    "\n",
    "            # m0 = margin_fn(ts, row_current, y0)\n",
    "\n",
    "            # active knobs print/save\n",
    "            active = []\n",
    "            for ch in (1,2,3):\n",
    "                f = float(row_current.get(f'Naphtha_chamber{ch}', 0.0))\n",
    "                rc= float(row_current.get(f'RCOT_chamber{ch}',  np.nan))\n",
    "                if f > 1.0 and np.isfinite(rc) and rc >= 800.0:\n",
    "                    active.append((f'RCOT_chamber{ch}', rc, f))\n",
    "            for ch in (4,5,6):\n",
    "                fN = float(row_current.get(f'Naphtha_chamber{ch}', 0.0))\n",
    "                rcN= float(row_current.get(f'RCOT_naphtha_chamber{ch}', np.nan))\n",
    "                if fN > 1.0 and np.isfinite(rcN) and rcN >= 800.0:\n",
    "                    active.append((f'RCOT_naphtha_chamber{ch}', rcN, fN))\n",
    "                fG = float(row_current.get(f'Gas Feed_chamber{ch}', 0.0))\n",
    "                rcG= float(row_current.get(f'RCOT_gas_chamber{ch}',     np.nan))\n",
    "                if fG > 1.0 and np.isfinite(rcG) and rcG >= 800.0:\n",
    "                    active.append((f'RCOT_gas_chamber{ch}', rcG, fG))\n",
    "            print(\"\\nActive RCOT knobs (name, rcot, flow_tph):\")\n",
    "            for name, rc, flow in active:\n",
    "                print(f\"  {name:24s}  {rc:7.2f} °C   flow={flow:7.3f} t/h\")\n",
    "            pd.DataFrame(active, columns=['knob','rcot_C','flow_tph']).assign(timestamp=ts)\\\n",
    "                .to_csv(AK_DIR / f\"active_{ts:%Y%m%d_%H%M}.csv\", index=False)\n",
    "\n",
    "            # optimize multi-knob (tuned α)\n",
    "            # res = opt.optimize_rcot_for_ts_multi(\n",
    "            #     ts=ts, row0=row_current,\n",
    "            #     gps=gps_dict, feature_cols_gp=feature_cols_gp,\n",
    "            #     total_spyro_yield_for_now=_spyro_ts, spyro_ctx=None,\n",
    "            #     price_provider=pp,\n",
    "            #     objective='per_hour',\n",
    "            #     naph_bounds=naph_b, gas_bounds=gas_b,\n",
    "            #     trust_delta_C=5.0,                      # ← gate controls trust\n",
    "            #     use_recycle_fixed_point=False, recycle_fn=None,\n",
    "            #     margin_mode='excel_delta', fg_constants=fg_consts,\n",
    "            #     alpha_overrides=overrides,\n",
    "            #     enable_de=True, enable_slsqp=True,\n",
    "            #     bounds_by_knob=bounds_by_knob           # ← NEW\n",
    "            # )\n",
    "\n",
    "            res = opt.optimize_rcot_for_ts_multi(\n",
    "                ts=ts, row0=row_current,\n",
    "                gps=gps_dict, feature_cols_gp=feature_cols_gp,\n",
    "                total_spyro_yield_for_now=total_spyro_yield_for_now, spyro_ctx=None,\n",
    "                price_provider=pp,\n",
    "                objective='per_hour',\n",
    "                naph_bounds=naph_b, gas_bounds=gas_b,\n",
    "                trust_delta_C=5.0,                      # ← your ±5 °C window\n",
    "                use_recycle_fixed_point=False, recycle_fn=None,\n",
    "                margin_mode='excel_delta', fg_constants=fg_consts,\n",
    "                alpha_overrides=None,                   # not used in anchored mode\n",
    "                enable_de=True, enable_slsqp=True,\n",
    "                bounds_by_knob=bounds_by_knob,\n",
    "\n",
    "                # NEW for anchored-mode\n",
    "                anchored_from_ml=True,\n",
    "                gp=gp, pipeline=pipeline, merged_lims=merged_lims, ml_cached=ml_cached,\n",
    "                alpha_default_for_anchor=0.0            # pure SRTO slopes\n",
    "            )\n",
    "\n",
    "\n",
    "            row_opt = res['row_opt']; y_opt = res['yields_opt']\n",
    "            m_base  = res['margin_current_per_h']; m_opt = res['margin_opt_per_h']; d_m = res['improvement_per_h']\n",
    "\n",
    "            print(\"\\n=== MULTI-KNOB RESULT ===\")\n",
    "            print(\"Status:\", res.get('status'))\n",
    "            print(\"ΔMargin $/h:\", f\"{d_m:,.2f}\")\n",
    "            print(\"RCOT* (per chamber):\")\n",
    "            for k,v in res['rcot_opt'].items():\n",
    "                cur = float(row_current.get(k, np.nan))\n",
    "                print(f\"  {k:24s}  {cur:7.2f} → {float(v):7.2f}  (Δ {float(v)-cur:+.2f})\")\n",
    "\n",
    "            # build flat row now\n",
    "            flat = {\n",
    "                'timestamp': ts, 'geometry': geom, 'status': res['status'],\n",
    "                'margin_baseline_per_h': float(m0),\n",
    "                'margin_opt_per_h':      float(m_opt),\n",
    "                'improvement_per_h':     float(d_m),\n",
    "                'margin_realized_per_h': float(m_real),\n",
    "            }\n",
    "            # rcots\n",
    "            rcot_cols = [f'RCOT_chamber{i}' for i in (1,2,3)] \\\n",
    "                      + [f'RCOT_naphtha_chamber{i}' for i in (4,5,6)] \\\n",
    "                      + [f'RCOT_gas_chamber{i}'     for i in (4,5,6)]\n",
    "            for c in rcot_cols:\n",
    "                flat[f'rcot_current_{c}'] = float(row_current.get(c, np.nan))\n",
    "            for k, v in res['rcot_opt'].items():\n",
    "                flat[f'rcot_opt_{k}'] = float(v)\n",
    "            # yields\n",
    "            for p in ['Ethylene','Propylene','MixedC4','RPG','Hydrogen','Tail_Gas']:\n",
    "                flat[f'{p}_current_tph'] = float(y0.get(f'{p}_prod_t+1', np.nan))\n",
    "                flat[f'{p}_opt_tph']     = float(y_opt.get(f'{p}_prod_t+1', np.nan))\n",
    "                flat[f'{p}_delta_tph']   = flat[f'{p}_opt_tph'] - flat[f'{p}_current_tph']\n",
    "            # align naming\n",
    "            flat['margin_current_per_h'] = float(m_base)\n",
    "\n",
    "            # snapshot JSON\n",
    "            snap = dict(\n",
    "                timestamp=str(ts), status=res.get('status'),\n",
    "                margins=dict(current=m_base, optimal=m_opt, delta=d_m),\n",
    "                rcot_opt=res.get('rcot_opt', {}),\n",
    "                yields_current={k: float(y0.get(k, np.nan)) for k in y0.keys()},\n",
    "                yields_opt={k: float(y_opt.get(k, np.nan)) for k in y_opt.keys()},\n",
    "            )\n",
    "            (SNAP_DIR/f\"multi_{ts:%Y%m%d_%H%M}.json\").write_text(json.dumps(snap, indent=2))\n",
    "\n",
    "            # RCOT moves\n",
    "            def _flow_for_knob(knob: str, r: pd.Series) -> float:\n",
    "                if knob.startswith('RCOT_chamber'):\n",
    "                    ch = int(knob.replace('RCOT_chamber',''))\n",
    "                    return float(r.get(f'Naphtha_chamber{ch}', 0.0))\n",
    "                if knob.startswith('RCOT_naphtha_chamber'):\n",
    "                    ch = int(knob.replace('RCOT_naphtha_chamber',''))\n",
    "                    return float(r.get(f'Naphtha_chamber{ch}', 0.0))\n",
    "                if knob.startswith('RCOT_gas_chamber'):\n",
    "                    ch = int(knob.replace('RCOT_gas_chamber',''))\n",
    "                    return float(r.get(f'Gas Feed_chamber{ch}', 0.0))\n",
    "                return 0.0\n",
    "            rcot_knobs = rcot_cols\n",
    "            moves = []\n",
    "            for knob in rcot_knobs:\n",
    "                rc_curr = float(row_current.get(knob, np.nan))\n",
    "                rc_opt  = float(res['rcot_opt'].get(knob, rc_curr))\n",
    "                flow    = _flow_for_knob(knob, row_current)\n",
    "                active_flag = bool((flow > 1.0) and np.isfinite(rc_curr) and (rc_curr >= 800.0))\n",
    "                moves.append(dict(timestamp=ts, knob=knob, flow_tph=flow,\n",
    "                                  rcot_current_C=rc_curr, rcot_opt_C=rc_opt,\n",
    "                                  delta_C=(rc_opt - rc_curr), active=active_flag))\n",
    "            df_moves = pd.DataFrame(moves)\n",
    "            if not df_moves.empty:\n",
    "                df_moves.to_csv(MOV_DIR / f\"rcot_moves_{ts:%Y%m%d_%H%M}.csv\", index=False)\n",
    "                MOVES_CSV = OUT_DIR / \"rcot_moves_all.csv\"\n",
    "                df_moves.to_csv(MOVES_CSV, mode='a', header=not MOVES_CSV.exists(), index=False)\n",
    "\n",
    "            # BEFORE/AFTER price audit print + save\n",
    "            def _prices_at(ts: pd.Timestamp, pp: opt.PriceProvider):\n",
    "                pr_c = {p: float(pp.get(ts, {'Ethylene':'Ethylene','Propylene':'Propylene','MixedC4':'Mixed C4','RPG':'RPG','Hydrogen':'Hydrogen','Tail_Gas':'Tail Gas'}[p], 0.0)) for p in ['Ethylene','Propylene','MixedC4','RPG','Hydrogen','Tail_Gas']}\n",
    "                pr_p = {'Mixed C4': pr_c['MixedC4'], 'Tail Gas': float(pp.get(ts, 'Tail Gas', 0.0))}\n",
    "                # pr_f = {'PN': float(pp.get(ts,'PN',0.0)), 'Gas Feed': float(pp.get(ts,'Gas Feed',0.0)),\n",
    "                #         'LPG': float(pp.get(ts,'LPG', float(pp.get(ts,'Gas Feed',0.0)))), 'MX Offgas': float(pp.get(ts,'MX Offgas',0.0)),\n",
    "                #         'Tail Gas': pr_p['Tail Gas']}\n",
    "                pr_f = {\n",
    "                    'PN':        float(pp.get(ts, 'PN', 0.0)),\n",
    "                    'Gas Feed':  float(pp.get(ts, 'Gas Feed', 0.0)),\n",
    "                    'LPG':       float(pp.get(ts, 'LPG', float(pp.get(ts,'Gas Feed',0.0)))),\n",
    "                    'MX Offgas': float(pp.get(ts, 'MX Offgas', 0.0)),\n",
    "                    'Fuel Gas':  float(pp.get(ts, 'Fuel Gas', 0.0)),  # ← add this\n",
    "                    'Tail Gas':  float(pp.get(ts, 'Tail Gas', 0.0)),  # (still fine to keep for revenue snapshot)\n",
    "                }\n",
    "\n",
    "\n",
    "                return pr_c, pr_p, pr_f\n",
    "\n",
    "            pr_c, pr_p, pr_f = _prices_at(ts, pp)\n",
    "            def _revenue(yields_abs, pr_c):\n",
    "                return sum(float(yields_abs.get(f'{p}_prod_t+1',0.0))*pr_c[p] for p in ['Ethylene','Propylene','MixedC4','RPG','Hydrogen','Tail_Gas'])\n",
    "            def _feeds(r, pr_f):\n",
    "                naph = sum(float(r.get(f'Naphtha_chamber{i}',0.0)) for i in range(1,7))\n",
    "                gasC = sum(float(r.get(f'Gas Feed_chamber{i}',0.0)) for i in (4,5,6))\n",
    "                fresh_lpg = float(r.get('FreshFeed_C3 LPG',0.0))\n",
    "                fresh_off = float(r.get('FreshFeed_MX Offgas',0.0))\n",
    "                if fresh_lpg>0 or fresh_off>0:\n",
    "                    return naph*pr_f['PN'] + fresh_lpg*pr_f['LPG'] + fresh_off*pr_f['MX Offgas']\n",
    "                return naph*pr_f['PN'] + gasC*pr_f['Gas Feed']\n",
    "            def _recycle(yields_abs, pr_f):\n",
    "                eth = float(yields_abs.get('Ethane_prod_t+1',0.0)); pro = float(yields_abs.get('Propane_prod_t+1',0.0))\n",
    "                return (eth + pro) * pr_f['LPG']\n",
    "            # ΔFG energy fixed baseline (rc_n0/rc_g0 from row_current)\n",
    "            def _per_side_rc_eff(r: pd.Series):\n",
    "                def _mean(keys, fkeys, rc_min=800.0, flow_thr=1.0):\n",
    "                    pairs = []\n",
    "                    for k, fk in zip(keys, fkeys):\n",
    "                        rc = float(r.get(k, np.nan)); f = float(r.get(fk, 0.0))\n",
    "                        if np.isfinite(rc) and rc >= rc_min and f > flow_thr:\n",
    "                            pairs.append((rc, f))\n",
    "                    if not pairs: return np.nan\n",
    "                    w = sum(f for _, f in pairs)\n",
    "                    return sum(rc*f for rc,f in pairs)/w if w>0 else np.nan\n",
    "                rc13   = _mean([f'RCOT_chamber{i}'         for i in (1,2,3)],\n",
    "                               [f'Naphtha_chamber{i}'      for i in (1,2,3)])\n",
    "                rcn456 = _mean([f'RCOT_naphtha_chamber{i}' for i in (4,5,6)],\n",
    "                               [f'Naphtha_chamber{i}'      for i in (4,5,6)])\n",
    "                rcg456 = _mean([f'RCOT_gas_chamber{i}'     for i in (4,5,6)],\n",
    "                               [f'Gas Feed_chamber{i}'     for i in (4,5,6)])\n",
    "                rc_n_eff = np.nanmean([rc13, rcn456]) if (np.isfinite(rc13) or np.isfinite(rcn456)) else np.nan\n",
    "                rc_g_eff = rcg456\n",
    "                naph = sum(float(r.get(f'Naphtha_chamber{i}', 0.0))  for i in range(1,7))\n",
    "                gas  = sum(float(r.get(f'Gas Feed_chamber{i}', 0.0)) for i in (4,5,6))\n",
    "                D    = max(float(naph + gas), 1e-9)\n",
    "                wN, wG = (naph / D), (gas / D)\n",
    "                return rc_n_eff, rc_g_eff, wN, wG, D\n",
    "            def _fg_abs(r: pd.Series):\n",
    "                for sk in ('Fuel_Gas','Fuel Gas','FG','FuelGas','Tail Gas','Tail_Gas'):\n",
    "                    try: return float(_spyro_ts(r, sk, ctx=None))\n",
    "                    except Exception: pass\n",
    "                return 0.0\n",
    "            def _override_rcot(r: pd.Series, rc_n=None, rc_g=None) -> pd.Series:\n",
    "                rr = r.copy()\n",
    "                if rc_n is not None:\n",
    "                    for ch in (1,2,3): rr[f'RCOT_chamber{ch}'] = float(rc_n)\n",
    "                    for ch in (4,5,6): rr[f'RCOT_naphtha_chamber{ch}'] = float(rc_n)\n",
    "                if rc_g is not None:\n",
    "                    for ch in (4,5,6): rr[f'RCOT_gas_chamber{ch}'] = float(rc_g)\n",
    "                return rr\n",
    "            rc_n0, rc_g0, _, _, _ = _per_side_rc_eff(row_current)\n",
    "            def _dfg_energy(row_like, yields_abs, rc_n0, rc_g0):\n",
    "                rc_n, rc_g, wN, wG, D = _per_side_rc_eff(row_like)\n",
    "                if not np.isfinite(rc_n): rc_n = float(fg_consts.rc_ref_naph)\n",
    "                if not np.isfinite(rc_g): rc_g = float(fg_consts.rc_ref_gas)\n",
    "                E_abs = float(yields_abs.get('Ethylene_prod_t+1',0.0))\n",
    "                P_abs = float(yields_abs.get('Propylene_prod_t+1',0.0))\n",
    "                FG_ab = _fg_abs(row_like)\n",
    "                rE, rP, rFG = E_abs/D, P_abs/D, FG_ab/D\n",
    "                r_base = _override_rcot(row_like, rc_n=rc_n0, rc_g=rc_g0)\n",
    "                # base_E = float(total_spyro_yield_for_now(r_base,'Ethylene',None))/D\n",
    "                # base_P = float(total_spyro_yield_for_now(r_base,'Propylene',None))/D\n",
    "                base_E = float(_spyro_ts(r_base, 'Ethylene', None)) / D\n",
    "                base_P = float(_spyro_ts(r_base, 'Propylene', None)) / D\n",
    "\n",
    "                base_FG= _fg_abs(r_base)/D\n",
    "                Cpw = float(fg_consts.cp_wavg_kcal_per_ton_K); HHV = float(fg_consts.fuel_gas_heat_content_kcal_per_ton)\n",
    "                rc_term = Cpw * (wN*(rc_n-rc_n0) + wG*(rc_g-rc_g0))\n",
    "                S = rc_term + (rE-base_E)*float(fg_consts.dH_eth_kcal_per_ton) \\\n",
    "                            + (rP-base_P)*float(fg_consts.dH_prop_kcal_per_ton) \\\n",
    "                            + (rFG-base_FG)*float(fg_consts.dH_fg_kcal_per_ton)\n",
    "                return float((S/HHV)*D)\n",
    "\n",
    "                # ── (A) Sequential anchored attribution (per knob → chamber) ──\n",
    "            def _anchored_for_row(r_like: pd.Series) -> dict:\n",
    "                return opt.anchored_expected_for_row(\n",
    "                    row_base=row_current, row_cand=r_like,\n",
    "                    gp=gp, pipeline=pipeline, merged_lims=merged_lims, ml_cached=ml_cached,\n",
    "                    alpha_default=0.0, alpha_overrides=None  # pure SRTO slope\n",
    "                )\n",
    "\n",
    "\n",
    "            # # ── (A) Sequential corrected attribution (per knob → summed by chamber) ──\n",
    "            # def _corrected_for_row(r_like: pd.Series) -> dict:\n",
    "            #     return opt.corrected_yields_for_row(\n",
    "            #         r_like, gps_dict, feature_cols_gp,\n",
    "            #         total_spyro_yield_for_now, spyro_ctx=None, alpha_overrides=overrides\n",
    "            #     )\n",
    "\n",
    "            # Build an order: biggest |ΔC| × flow first\n",
    "            rcot_knobs = [f'RCOT_chamber{i}' for i in (1,2,3)] \\\n",
    "                    + [f'RCOT_naphtha_chamber{i}' for i in (4,5,6)] \\\n",
    "                    + [f'RCOT_gas_chamber{i}'     for i in (4,5,6)]\n",
    "            moves_df = pd.DataFrame({\n",
    "                'knob': rcot_knobs,\n",
    "                'rc_from': [float(row_current.get(k, np.nan)) for k in rcot_knobs],\n",
    "                'rc_to':   [float(res['rcot_opt'].get(k, row_current.get(k, np.nan))) for k in rcot_knobs],\n",
    "                'flow':    [_flow_for_knob(k, row_current) for k in rcot_knobs],\n",
    "            })\n",
    "            moves_df['deltaC_abs'] = (moves_df['rc_to'] - moves_df['rc_from']).abs()\n",
    "            order = (moves_df.sort_values(['deltaC_abs','flow'], ascending=[False, False])['knob']\n",
    "                    .tolist())\n",
    "\n",
    "            #         # ── (A) Sequential anchored attribution (per knob → chamber) ──\n",
    "            # def _anchored_for_row(r_like: pd.Series) -> dict:\n",
    "            #     return opt.anchored_expected_for_row(\n",
    "            #         row_base=row_current, row_cand=r_like,\n",
    "            #         gp=gp, pipeline=pipeline, merged_lims=merged_lims, ml_cached=ml_cached,\n",
    "            #         alpha_default=0.0, alpha_overrides=None  # pure SRTO slope\n",
    "            #     )\n",
    "\n",
    "\n",
    "            r_now = row_current.copy()\n",
    "            y_now = _anchored_for_row(r_now)\n",
    "            m_now = margin_fn(ts, r_now, y_now)\n",
    "\n",
    "            attr_rows = []\n",
    "            for k in order:\n",
    "                rc_from = float(r_now.get(k, np.nan))\n",
    "                rc_to   = float(res['rcot_opt'].get(k, rc_from))\n",
    "                if not np.isfinite(rc_to) or rc_to == rc_from:\n",
    "                    continue\n",
    "                r_next = r_now.copy(); r_next[k] = rc_to\n",
    "                y_next = _anchored_for_row(r_next)\n",
    "                m_next = margin_fn(ts, r_next, y_next)\n",
    "\n",
    "                d = {p: float(y_next.get(f'{p}_prod_t+1',0.0)) - float(y_now.get(f'{p}_prod_t+1',0.0))\n",
    "                    for p in ['Ethylene','Propylene','MixedC4','RPG','Hydrogen','Tail_Gas']}\n",
    "\n",
    "                # optional ΔFG step (same baseline as audit)\n",
    "                try:\n",
    "                    dfg_step = _dfg_energy(r_next, y_next, rc_n0, rc_g0) - _dfg_energy(r_now, y_now, rc_n0, rc_g0)\n",
    "                except Exception:\n",
    "                    dfg_step = 0.0\n",
    "\n",
    "                attr_rows.append({\n",
    "                    'knob': k, 'chamber': _ch_from_knob(k),\n",
    "                    'rc_from_C': rc_from, 'rc_to_C': rc_to,\n",
    "                    'flow_tph': _flow_for_knob(k, r_now),\n",
    "                    'd_Ethylene_tph': d['Ethylene'],\n",
    "                    'd_Propylene_tph': d['Propylene'],\n",
    "                    'd_MixedC4_tph':   d['MixedC4'],\n",
    "                    'd_RPG_tph':       d['RPG'],\n",
    "                    'd_Hydrogen_tph':  d['Hydrogen'],\n",
    "                    'd_TailGas_tph':   d['Tail_Gas'],\n",
    "                    'd_fg_tph': dfg_step,\n",
    "                    'd_margin_per_h': float(m_next - m_now),\n",
    "                })\n",
    "                r_now, y_now, m_now = r_next, y_next, m_next\n",
    "\n",
    "            df_attr = pd.DataFrame(attr_rows)\n",
    "            if not df_attr.empty:\n",
    "                df_attr.to_csv(ATTR_DIR / f\"knob_attr_corrected_{ts:%Y%m%d_%H%M}.csv\", index=False)\n",
    "                ch_sum = (df_attr.groupby('chamber')[[\n",
    "                            'd_Ethylene_tph','d_Propylene_tph','d_MixedC4_tph',\n",
    "                            'd_RPG_tph','d_TailGas_tph','d_Hydrogen_tph','d_margin_per_h'\n",
    "                        ]].sum().sort_index())\n",
    "                print(\"\\n--- Expected Δ by chamber (corrected; sums to total) ---\")\n",
    "                print(ch_sum.round(4).to_string())\n",
    "\n",
    "            # ── (B) Physics per-leg delta (SRTO) → chamber/feed ──\n",
    "            comp_row = gp._comp_row_for_ts(merged_lims, ts)\n",
    "            spot_base = pipeline.predict_spot_plant(row_current, comp_row, feed_thr=0.1)\n",
    "            spot_opt  = pipeline.predict_spot_plant(row_opt,     comp_row, feed_thr=0.1)\n",
    "\n",
    "            dfb = _legs_to_df(spot_base.get('legs', []))\n",
    "            dfa = _legs_to_df(spot_opt.get('legs', []))\n",
    "            leg = dfa.merge(dfb, on=['chamber','feed'], how='outer', suffixes=('_after','_before')).fillna(0.0)\n",
    "            for p in ['Ethylene','Propylene','MixedC4','RPG','Tail_Gas','Hydrogen']:\n",
    "                leg[f'd_{p}_tph'] = leg[f'{p}_tph_after'] - leg[f'{p}_tph_before']\n",
    "            leg.to_csv(ATTR_DIR / f\"srto_leg_delta_{ts:%Y%m%d_%H%M}.csv\", index=False)\n",
    "\n",
    "            ch_phys = (leg.groupby('chamber')[[f'd_{p}_tph' for p in ['Ethylene','Propylene','MixedC4','RPG','Tail_Gas','Hydrogen']]]\n",
    "                    .sum().sort_index())\n",
    "            print(\"\\n--- Physics Δ by chamber (SRTO legs) ---\")\n",
    "            print(ch_phys.round(4).to_string())\n",
    "\n",
    "\n",
    "\n",
    "            # compute summary & save\n",
    "            items = pd.DataFrame([\n",
    "                dict(product=p.replace('MixedC4','Mixed C4').replace('Tail_Gas','Tail Gas'),\n",
    "                     qty_before=float(y0.get(f'{p}_prod_t+1',0.0)),\n",
    "                     qty_after= float(y_opt.get(f'{p}_prod_t+1',0.0)),\n",
    "                     price=pr_c[p],\n",
    "                     rev_before=float(y0.get(f'{p}_prod_t+1',0.0))*pr_c[p],\n",
    "                     rev_after=float(y_opt.get(f'{p}_prod_t+1',0.0))*pr_c[p],\n",
    "                     rev_delta=(float(y_opt.get(f'{p}_prod_t+1',0.0))-float(y0.get(f'{p}_prod_t+1',0.0)))*pr_c[p]\n",
    "                     )\n",
    "                for p in ['Ethylene','Propylene','MixedC4','RPG','Hydrogen','Tail_Gas']\n",
    "            ])\n",
    "\n",
    "            rev_b = _revenue(y0, pr_c);     rev_a = _revenue(y_opt, pr_c)\n",
    "            feed_b= _feeds(row_current, pr_f);     feed_a= _feeds(row_opt, pr_f)\n",
    "            rec_b = _recycle(y0, pr_f);     rec_a=  _recycle(y_opt, pr_f)\n",
    "            dfg_b = _dfg_energy(row_current, y0, rc_n0, rc_g0);   dfg_a = _dfg_energy(row_opt, y_opt, rc_n0, rc_g0)\n",
    "            # tg_price = pr_f['Tail Gas']\n",
    "            fg_price = pr_f.get('Fuel Gas', pr_f.get('Tail Gas', 0.0))  # prefer Fuel Gas, fallback Tail Gas if needed\n",
    "\n",
    "            fgc_b = dfg_b * fg_price;       fgc_a = dfg_a * fg_price\n",
    "            m_b   = rev_b - feed_b + rec_b - fgc_b\n",
    "            m_a   = rev_a - feed_a + rec_a - fgc_a\n",
    "\n",
    "            print(\"\\n=== PRICE SNAPSHOT @\", ts, \"===\")\n",
    "            # snap = {k: (pr_p.get(k) if k in pr_p else pr_c.get(k.replace(\" \",\"_\"), np.nan)) for k in ['Ethylene','Propylene','Mixed C4','RPG','Hydrogen','Tail Gas']}\n",
    "            # snap.update({k: pr_f[k] for k in ['PN','Gas Feed','LPG','MX Offgas']})\n",
    "            # print(snap)\n",
    "\n",
    "            # snap = {k: pr_c.get(k.replace(\" \",\"_\"), np.nan) for k in ['Ethylene','Propylene','Mixed C4','RPG','Hydrogen']}\n",
    "            # snap['Tail Gas'] = pr_f['Tail Gas']\n",
    "            # snap['Fuel Gas'] = pr_f['Fuel Gas']  # ← show it explicitly\n",
    "            # snap.update({k: pr_f[k] for k in ['PN','Gas Feed','LPG','MX Offgas']})\n",
    "            snap = {\n",
    "                'Ethylene':  pr_c['Ethylene'],\n",
    "                'Propylene': pr_c['Propylene'],\n",
    "                'Mixed C4':  pr_c['MixedC4'],   # correct key\n",
    "                'RPG':       pr_c['RPG'],\n",
    "                'Hydrogen':  pr_c['Hydrogen'],\n",
    "                'Tail Gas':  pr_f['Tail Gas'],\n",
    "                'Fuel Gas':  pr_f['Fuel Gas'],\n",
    "                'PN':        pr_f['PN'],\n",
    "                'Gas Feed':  pr_f['Gas Feed'],\n",
    "                'LPG':       pr_f['LPG'],\n",
    "                'MX Offgas': pr_f['MX Offgas'],\n",
    "            }            \n",
    "            print(snap)\n",
    "\n",
    "\n",
    "            print(\"\\n=== BEFORE vs AFTER (per product) ===\")\n",
    "            print(items[['product','qty_before','qty_after','price','rev_before','rev_after','rev_delta']]\n",
    "                  .sort_values('product').to_string(index=False, float_format=lambda x: f\"{x:,.3f}\"))\n",
    "\n",
    "            print(\"\\n=== SUMMARY ($/h) ===\")\n",
    "            print(f\"Revenue      : {rev_b:,.2f}  →  {rev_a:,.2f}   (Δ {rev_a-rev_b:+,.2f})\")\n",
    "            print(f\"Feed cost    : {feed_b:,.2f} →  {feed_a:,.2f}  (Δ {feed_a-feed_b:+,.2f})\")\n",
    "            print(f\"Recycle cred.: {rec_b:,.2f} →  {rec_a:,.2f}  (Δ {rec_a-rec_b:+,.2f})\")\n",
    "            print(f\"ΔFG (tph)    : {dfg_b:.6f} → {dfg_a:.6f} (Δ {dfg_a-dfg_b:+.6f}) × Fuel Gas={fg_price:,.2f} → FG cost Δ: {(fgc_a-fgc_b):+,.2f}\")\n",
    "            print(f\"MARGIN       : {m_b:,.2f} → {m_a:,.2f} (Δ {m_a-m_b:+,.2f})\")\n",
    "\n",
    "            # save\n",
    "            items.to_csv(AUD_DIR / f\"audit_items_{ts:%Y%m%d_%H%M}.csv\", index=False)\n",
    "            summary = dict(\n",
    "                ts=str(ts), prices=dict(canonical=pr_c, feeds=pr_f),\n",
    "                revenue_before=rev_b, revenue_after=rev_a,\n",
    "                feed_before=feed_b, feed_after=feed_a,\n",
    "                recycle_before=rec_b, recycle_after=rec_a,\n",
    "                dfg_tph_before=dfg_b, dfg_tph_after=dfg_a, fuelgas_price=fg_price,\n",
    "                fg_cost_before=fgc_b, fg_cost_after=fgc_a,\n",
    "                margin_before=m_b, margin_after=m_a,\n",
    "                rcot_opt=res.get('rcot_opt',{})\n",
    "            )\n",
    "            (AUD_DIR/f\"audit_summary_{ts:%Y%m%d_%H%M}.json\").write_text(json.dumps(summary, indent=2))\n",
    "\n",
    "            # Save curves (overrides-only α; rc0-injected)\n",
    "            try:\n",
    "                for geom_audit in [_geometry_label_for_row(row_current)]:\n",
    "                    setter = {'LF_NAPH': gpmod.rcot_setter_lf_naph,\n",
    "                              'GF_GAS':  gpmod.rcot_setter_gf_gas,\n",
    "                              'GF_HYB_NAPH': gpmod.rcot_setter_hybrid}[geom_audit]\n",
    "                    rc_lo, rc_hi = RC_BOUNDS.get(geom_audit, (810, 853))\n",
    "                    rc_grid = _rc_grid_for(row_current, geom_audit, rc_lo, rc_hi, points=15)\n",
    "                    curve, x_row = gpmod.anchored_curve_at_ts(\n",
    "                        gp=gp, X_12h=X_12h, merged_lims=merged_lims, pipeline=pipeline,\n",
    "                        ml=ml_cached, ts=ts, rcot_setter=setter, rc_grid=rc_grid,\n",
    "                        use_gp_delta=True, alpha=0.0\n",
    "                    )\n",
    "                    curve.to_csv(CURVES_DIR / f\"curve_{ts:%Y%m%d_%H%M}_{geom_audit}.csv\", index=False)\n",
    "                    # slope fidelity at save time\n",
    "                    rows = []\n",
    "                    for p in gpmod.PRODUCTS:\n",
    "                        sc, cov = _robust_slope_metrics(curve, p)\n",
    "                        a_col, c_col = f'{p}_ANCHOR_tph', f'{p}_CORR_tph'\n",
    "                        diff = (curve[c_col].astype(float) - curve[a_col].astype(float)).abs().to_numpy(float) if (a_col in curve and c_col in curve) else np.array([np.nan])\n",
    "                        rows.append({'timestamp': ts, 'geometry': geom_audit, 'product': p,\n",
    "                                     'slope_corr': sc, 'sign_cov': cov, 'anchor_miss_min': float(np.nanmin(diff))})\n",
    "                    pd.DataFrame(rows).to_csv(CURVES_DIR / f\"audit_{ts:%Y%m%d_%H%M}_{geom_audit}.csv\", index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Curve/audit save failed at {ts}: {e}\")\n",
    "\n",
    "            # persist recommendations row\n",
    "            rec_rows.append(flat)\n",
    "\n",
    "            # ---------- CLOSED-LOOP: apply setpoints to state & write simulated lags ----------\n",
    "            # if mode == 'closed_loop':\n",
    "            #     # apply setpoints from ts either at next stamp or next day\n",
    "            #     if apply_timing == 'next_stamp':\n",
    "            #         # hold from the next stamp onward\n",
    "            #         # find next index\n",
    "            #         idx = X_state.index\n",
    "            #         next_mask = idx > ts\n",
    "            #         if next_mask.any():\n",
    "            #             t1 = idx[next_mask][0]\n",
    "            #             rcot_schedule.append((t1, res['rcot_opt']))\n",
    "            #             # set & hold until changed later (we’ll re-apply schedule end-to-end after day)\n",
    "            #             for knob, val in res['rcot_opt'].items():\n",
    "            #                 if knob in X_state.columns:\n",
    "            #                     X_state.loc[idx >= t1, knob] = float(val)\n",
    "            #     else:  # 'next_day'\n",
    "            #         next_day = (pd.Timestamp(ts).normalize() + pd.Timedelta(days=1))\n",
    "            #         rcot_schedule.append((next_day, res['rcot_opt']))\n",
    "            #         for knob, val in res['rcot_opt'].items():\n",
    "            #             if knob in X_state.columns:\n",
    "            #                 X_state.loc[X_state.index >= next_day, knob] = float(val)\n",
    "\n",
    "            #     # write simulated corrected yields for this stamp to Y_sim_state (for ML lags)\n",
    "            #     if Y_sim_state is not None:\n",
    "            #         for p in PRODS_INTERNAL:\n",
    "            #             Y_sim_state.at[ts, f'{p}_prod_t+1'] = float(y0.get(f'{p}_prod_t+1', np.nan))\n",
    "\n",
    "            # ---------- CLOSED-LOOP: apply setpoints to state & write simulated lags ----------\n",
    "            if mode == 'closed_loop':\n",
    "                knobs_applied = {k: float(v) for k, v in res['rcot_opt'].items()}\n",
    "\n",
    "                if apply_timing == 'next_stamp':\n",
    "                    # apply from the immediately following index onward\n",
    "                    idx = X_state.index\n",
    "                    next_mask = idx > ts\n",
    "                    if next_mask.any():\n",
    "                        t1 = idx[next_mask][0]\n",
    "                        rcot_schedule.append((t1, knobs_applied))\n",
    "                        for knob, val in knobs_applied.items():\n",
    "                            if knob in X_state.columns:\n",
    "                                X_state.loc[idx >= t1, knob] = val\n",
    "                        # sanity print: current vs next\n",
    "                        klist = list(knobs_applied.keys())\n",
    "                        now_vals  = X_state.loc[ts,  klist].to_dict()\n",
    "                        next_vals = X_state.loc[t1, klist].to_dict()\n",
    "                        print(f\"[APPLIED next_stamp] {ts} -> {t1}\")\n",
    "                        print(\"  rcots@ts   :\", now_vals)\n",
    "                        print(\"  rcots@next :\", next_vals)\n",
    "                else:  # 'next_day'\n",
    "                    next_day = ts.normalize() + pd.Timedelta(days=1)\n",
    "                    rcot_schedule.append((next_day, knobs_applied))\n",
    "                    for knob, val in knobs_applied.items():\n",
    "                        if knob in X_state.columns:\n",
    "                            X_state.loc[X_state.index >= next_day, knob] = val\n",
    "                    print(f\"[SCHEDULED next_day] {ts} -> {next_day}: {knobs_applied}\")\n",
    "\n",
    "                # write simulated corrected yields for this stamp to Y_sim_state (for ML lags)\n",
    "                if Y_sim_state is not None:\n",
    "                    for p in PRODS_INTERNAL:\n",
    "                        Y_sim_state.at[ts, f'{p}_prod_t+1'] = float(y0.get(f'{p}_prod_t+1', np.nan))\n",
    "\n",
    "\n",
    "        # append day’s rows\n",
    "        if rec_rows:\n",
    "            df_new = pd.DataFrame(rec_rows)\n",
    "            _safe_merge_csv(OPT_REC_CSV, df_new, key='timestamp')\n",
    "\n",
    "    # --------- END OF RUN: counterfactual check (apply schedule and simulate once) ---------\n",
    "    if Path(OPT_REC_CSV).exists():\n",
    "        recs = pd.read_csv(OPT_REC_CSV, parse_dates=['timestamp']).sort_values('timestamp')\n",
    "        schedule = build_rcot_schedule_from_recs(recs)\n",
    "        X_sim = apply_schedule_to_X(X_12h, schedule, start=start, end=end, hold=\"hold_until_next\")\n",
    "        # NOTE: use alpha_overrides=None here to avoid last-stamp overrides affecting the whole horizon\n",
    "        # You can extend to per-stamp α later by reading your fidelity CSVs per ts.\n",
    "        # Fit a fresh GP on historical (or you can reuse the last gp; here we reuse last gp objects)\n",
    "        # Simulate corrected yields + margin\n",
    "        Y_sim, M_sim = simulate_path_corrected(\n",
    "            X_sim=X_sim, merged_lims=merged_lims, pipeline=pipeline,\n",
    "            gp=gp, gps_dict=gps_dict, feature_cols_gp=feature_cols_gp,\n",
    "            price_provider=pp, total_spyro_yield_for_now=total_spyro_yield_for_now,\n",
    "            fg_consts=fg_consts, alpha_overrides=None,\n",
    "            start=start, end=end\n",
    "        )\n",
    "        X_sim.to_csv(CF_DIR / \"X_sim_rcot_applied.csv\")\n",
    "        Y_sim.to_csv(CF_DIR / \"Y_sim_corrected.csv\")\n",
    "        M_sim.to_csv(CF_DIR / \"M_sim_margin.csv\")\n",
    "\n",
    "        # quick comparison sample\n",
    "        if 'margin_baseline_per_h' in recs.columns:\n",
    "            compare = (pd.DataFrame({'margin_hist': recs.set_index('timestamp')['margin_baseline_per_h']})\n",
    "                        .join(M_sim.rename(columns={'margin_per_h':'margin_sim'}), how='inner'))\n",
    "            print(\"\\n--- Margin hist vs sim (first 6 rows) ---\")\n",
    "            print(compare.head(6).to_string())\n",
    "\n",
    "    print(\"✅ Production run complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6b0b7",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cda512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1376, 100) (1376, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Downloads\\EFOM\\src\\data_loading.py:425: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df['month'] = df['timestamp'].dt.to_period('M').dt.to_timestamp()\n"
     ]
    }
   ],
   "source": [
    "import src.data_loading as dl; reload(dl)\n",
    "from src.data_loading import DataPaths, ResampleConfig, DataPipeline\n",
    "\n",
    "paths = DataPaths(\n",
    "    input_dir=Path(\"input\"), inter_dir=Path(\"intermediate\"),\n",
    "    prod_excel=\"1. 생산량 Data_'23.07~'25.05_R1_송부용.xlsx\",\n",
    "    furn_excel=\"2. Furnace Data_'23.07~'25.05_R0.xlsx\",\n",
    "    nap_excel =\"Nap Feed 조성분석값.xlsx\",\n",
    "    gas_excel =\"Gas Feed 조성분석값.xlsx\",\n",
    "    recycle_excel=\"6. 에탄 및 프로판 데이터.xlsx\",\n",
    "    # cost_excel=\"마진가격_vModel_v250625.xlsx\",\n",
    "    price_csv= \"price.csv\",\n",
    "    util_excel=\"#1ECU 유틸리티사용량일별데이터.xlsx\",\n",
    "    fresh_excel=\"7. Gas Furnace Feed Data_'23.07~'25.05_r2.xlsx\",\n",
    "\n",
    "    # PKL caches (optional)\n",
    "    prod_pkl=\"df_production_v4.pkl\", furn_pkl=\"furnace.pkl\",\n",
    "    nap_pkl =\"df_feed_naptha.pkl\", gas_pkl =\"df_feed_gas.pkl\",\n",
    "    fresh_pkl= 'df_feed_fresh_v3.pkl', rec_pkl =\"df_recycle.pkl\",\n",
    "    prod_header=2, furn_header=2, nap_header=1, gas_header=1, rec_header=4, fresh_header=3\n",
    ")\n",
    "cfg = ResampleConfig(hour_freq='h', win12_freq='12h', win12_offset='9h')\n",
    "\n",
    "\n",
    "feature_rename = {\n",
    "    # map your util feature names → canonical (only if you use util models)\n",
    "    'Naph': 'Naphtha_chamber1', 'T-DAO': 'T-DAO_chamber1', 'DS': 'DS_chamber1',\n",
    "    'RCOT Ave.': 'RCOT_chamber1', 'Excess O2': \"Excess O2_chamber1\",\n",
    "    'Naph.1': 'Naphtha_chamber2', 'T-DAO.1': 'T-DAO_chamber2','DS.1': 'DS_chamber2',\n",
    "    'RCOT Ave..1': 'RCOT_chamber2', 'Excess O2.1': \"Excess O2_chamber2\",\n",
    "    'Naph.2': 'Naphtha_chamber3', 'T-DAO.2': 'T-DAO_chamber3','DS.2': 'DS_chamber3',\n",
    "    'RCOT Ave..2': 'RCOT_chamber3', 'Excess O2.2': \"Excess O2_chamber3\",\n",
    "    'Naph.3': 'Naphtha_chamber4', 'GAS': 'Gas Feed_chamber4','DS.3': 'DS_chamber4',\n",
    "    'RCOT Ave..3': 'RCOT_chamber4', 'Excess O2.3': \"Excess O2_chamber4\",\n",
    "    'Naph.4': 'Naphtha_chamber5', 'GAS.1': 'Gas Feed_chamber5','DS.4': 'DS_chamber5',\n",
    "    'RCOT Ave..4': 'RCOT_chamber5', 'Excess O2.4': \"Excess O2_chamber5\",\n",
    "    'Naph.5': 'Naphtha_chamber6', 'GAS.2': 'Gas Feed_chamber6','DS.5': 'DS_chamber6',\n",
    "    'RCOT Ave..5': 'RCOT_chamber6', 'Excess O2.5': \"Excess O2_chamber6\",\n",
    "}\n",
    "target_rename  = { 'Unnamed: 36':'steam','ECU F/G':'fuel_gas','ECU Elec..1':'electricity' }\n",
    "\n",
    "dp = DataPipeline(paths, cfg).run(feature_rename, target_rename)\n",
    "art = dp.artifacts()\n",
    "X_12h, Y_12h, util_df, prices_df = art['X_12h'], art['Y_12h'], art['util_df'], art['price_df']\n",
    "\n",
    "# clamp horizon (LIMS)\n",
    "X_12h = X_12h.loc[:END]\n",
    "Y_12h = Y_12h.loc[:END]\n",
    "print(X_12h.shape, Y_12h.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1a76b",
   "metadata": {},
   "source": [
    "## 2) LIMS + SRTO pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b8f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Downloads\\EFOM\\src\\data_loading.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feed_gas['date'] = pd.to_datetime(feed_gas['date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "from src.data_loading import load_feed_data\n",
    "\n",
    "merged_lims = load_feed_data(\n",
    "    nap_path=paths.input_dir / \"복사본 (2024-25) ECU 투입 납사 세부성상-wt%.xlsx\",\n",
    "    gas_path=paths.input_dir / \"Gas Feed 조성분석값.xlsx\", header=1\n",
    ")\n",
    "merged_lims['date'] = pd.to_datetime(merged_lims['date'], errors='coerce')\n",
    "merged_lims = merged_lims.dropna(subset=['date']).sort_values('date')\n",
    "\n",
    "gas_cols = [c for c in ['Ethylene','Ethane','Propylene','Propane','n-Butane','i-Butane'] if c in merged_lims.columns]\n",
    "zr = (merged_lims[gas_cols].sum(axis=1) == 0)\n",
    "merged_lims.loc[zr, gas_cols] = np.nan\n",
    "merged_lims[gas_cols] = merged_lims[gas_cols].ffill().bfill()\n",
    "merged_lims = merged_lims.iloc[4:]  # keep (as you had)\n",
    "\n",
    "# SRTO DLL pipeline (plant spot)\n",
    "from src.srto_pipeline import SRTOConfig, RCOTSweepConfig, FeedConfig, SRTOPipeline\n",
    "from src.srto_components import component_index, MW\n",
    "dll_folder = Path(r\"C:\\Program Files\\Pyrotec\\SRTO\")\n",
    "selected_spy7 = [\n",
    "    dll_folder / \"01. GF_HYBRID MODE_SRTO7_NAPH.SPY7\",\n",
    "    dll_folder / \"04. LF_NAPH MODE_SRTO7.SPY7\",\n",
    "    dll_folder / \"07. GF_GAS MODE_SRTO7.SPY7\",\n",
    "]\n",
    "srto_config  = SRTOConfig(dll_folder, selected_spy7, component_index, MW)\n",
    "sweep_config = RCOTSweepConfig(rcot_min=790.0, rcot_max=900.0, rcot_step=2.0,\n",
    "                               chunk_size=10, n_jobs=6, save_checkpoints=True)\n",
    "feed_config  = FeedConfig(gas_components=gas_cols)\n",
    "pipeline     = SRTOPipeline(srto_config, sweep_config, feed_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b011b976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_12h_with_lims shape: (1376, 110)\n",
      "Missing after merge: {'Paraffins': 368, 'Olefins': 368, 'Naphthenes': 368, 'Aromatics': 368, 'Ethylene': 368, 'Ethane': 368, 'Propylene': 368, 'Propane': 368, 'n-Butane': 368, 'i-Butane': 368}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_21176\\562457764.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged[c] = merged[c].fillna(asof[c])\n"
     ]
    }
   ],
   "source": [
    "pona_cols = ['Paraffins','Olefins','Naphthenes','Aromatics']\n",
    "\n",
    "# Merge X_12h with merged_lims per AM/PM rule:\n",
    "# hour < 12 -> use previous day's LIMS, else use same day's LIMS; fallback to asof if day-join misses rows.\n",
    "x = X_12h.copy()\n",
    "ts = x.index.to_series()\n",
    "lims_date = ts.dt.normalize()\n",
    "lims_date = lims_date.where(ts.dt.hour >= 12, lims_date - pd.Timedelta(days=1))\n",
    "x = x.assign(lims_date=lims_date.values)\n",
    "\n",
    "m = merged_lims.copy()\n",
    "m['lims_date'] = pd.to_datetime(m['date'], errors='coerce').dt.normalize()\n",
    "m_daily = m.sort_values('date').groupby('lims_date', as_index=False).last()\n",
    "\n",
    "keep = pona_cols + gas_cols\n",
    "m_sel = m_daily[['lims_date'] + keep]\n",
    "\n",
    "xr = x.reset_index()\n",
    "idx_name = xr.columns[0]   # original timestamp column name\n",
    "merged = xr.merge(m_sel, on='lims_date', how='left').set_index(idx_name)\n",
    "merged.index.name = X_12h.index.name\n",
    "\n",
    "# fallback: fill any remaining NaNs with the most recent earlier merged_lims record\n",
    "if merged[keep].isna().any().any():\n",
    "    mr = m.sort_values('date')[['date'] + keep].rename(columns={'date': 'lims_ts'})\n",
    "    xr_ts = xr.copy(); xr_ts['ts'] = pd.to_datetime(xr_ts[idx_name])\n",
    "    asof = pd.merge_asof(xr_ts.sort_values('ts'),\n",
    "                         mr.sort_values('lims_ts'),\n",
    "                         left_on='ts', right_on='lims_ts', direction='backward').set_index(idx_name)\n",
    "    for c in keep:\n",
    "        merged[c] = merged[c].fillna(asof[c])\n",
    "\n",
    "X_12h_with_lims = X_12h.join(merged[keep])\n",
    "print('X_12h_with_lims shape:', X_12h_with_lims.shape)\n",
    "print('Missing after merge:', X_12h_with_lims[keep].isna().sum().to_dict())\n",
    "\n",
    "gas_rename = {c: f\"{c}_gas\" for c in gas_cols}  # e.g., 'Ethane' -> 'Ethane_gas'\n",
    "X_12h_with_lims = X_12h_with_lims.rename(columns=gas_rename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb073a90",
   "metadata": {},
   "source": [
    "## 3) Rolling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb250d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- lightweight memo around total_spyro_yield_for_now ---\n",
    "class SpyroMemo:\n",
    "    def __init__(self, fn, key_cols=None, decimals=4, maxsize=200000):\n",
    "        self.fn = fn\n",
    "        self.key_cols = tuple(key_cols) if key_cols is not None else None  # ensure tuple\n",
    "        self.dec = decimals\n",
    "        self.cache = {}\n",
    "        self.maxsize = maxsize\n",
    "\n",
    "    def _select_cols(self, row: pd.Series):\n",
    "        if self.key_cols is None:\n",
    "            # stable, hashable selection\n",
    "            return tuple(\n",
    "                c for c in row.index\n",
    "                if c.startswith('RCOT')\n",
    "                or c.startswith('Naphtha_chamber')\n",
    "                or c.startswith('Gas Feed_chamber')\n",
    "            )\n",
    "        return self.key_cols\n",
    "\n",
    "    def _to_num(self, x):\n",
    "        try:\n",
    "            v = float(x)\n",
    "        except Exception:\n",
    "            v = 0.0\n",
    "        # handle NaN\n",
    "        if v != v:  # NaN check without importing math\n",
    "            v = 0.0\n",
    "        return round(v, self.dec)\n",
    "\n",
    "    def _sig(self, row: pd.Series, short_key: str):\n",
    "        cols = self._select_cols(row)                # tuple, hashable\n",
    "        vals = tuple(self._to_num(row.get(c, 0.0)) for c in cols)\n",
    "        return (short_key, cols, vals)               # fully hashable\n",
    "\n",
    "    def __call__(self, row: pd.Series, short_key: str, ctx=None):\n",
    "        k = self._sig(row, short_key)\n",
    "        v = self.cache.get(k)\n",
    "        if v is not None:\n",
    "            return v\n",
    "        v = self.fn(row, short_key, ctx=ctx)\n",
    "        if len(self.cache) < self.maxsize:\n",
    "            self.cache[k] = v\n",
    "        return v\n",
    "\n",
    "# wrap it\n",
    "# total_spyro_yield_for_now = SpyroMemo(total_spyro_yield_for_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d138d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RCOT groups so setters touch the right columns\n",
    "gpmod.set_rcot_groups_from_columns(X_12h.columns)\n",
    "\n",
    "# Prices\n",
    "pp = opt.PriceProvider(prices_df)\n",
    "\n",
    "# If you haven't defined this yet, define a minimal SPYRO wrapper (ctx not required)\n",
    "_SHORT_TO_SRTO = {\n",
    "    'Ethylene':'Ethylene','Propylene':'Propylene','MixedC4':'MixedC4','RPG':'RPG',\n",
    "    'Ethane':'Ethane','Propane':'Propane',\n",
    "    'Fuel_Gas':'Fuel_Gas','Fuel Gas':'Fuel_Gas','FG':'Fuel_Gas','FuelGas':'Fuel_Gas',\n",
    "    'Tail Gas':'Tail_Gas', 'Tail_Gas' :'Tail_Gas'\n",
    "}\n",
    "def total_spyro_yield_for_now(row_like: pd.Series, short_key: str, ctx=None) -> float:\n",
    "    ts = getattr(row_like, 'name', None)\n",
    "    if ts is None: return 0.0\n",
    "    comp_row = merged_lims.loc[merged_lims['date'] <= ts].iloc[-1]\n",
    "    spot = pipeline.predict_spot_plant(row_like, comp_row, feed_thr=0.1)\n",
    "    if spot.get('status') != 'ok': return 0.0\n",
    "    key = _SHORT_TO_SRTO.get(short_key, short_key)\n",
    "    return float(spot['totals_tph'].get(key, 0.0))\n",
    "\n",
    "# Excel-delta margin wrapper (uses opt.delta_fg_excel by default)\n",
    "margin_excel = opt.make_margin_fn_excel_delta(\n",
    "    price_provider=pp,\n",
    "    total_spyro_yield_for_now=total_spyro_yield_for_now,\n",
    "    spyro_ctx=None,                                  # SPYRO_CTX can be None\n",
    "    fg_constants=opt.FuelGasConstants())\n",
    "\n",
    "# Bounds by geometry\n",
    "RC_BOUNDS = {\n",
    "    'LF_NAPH': (830.0, 853.0),\n",
    "    'GF_GAS':  (860.0, 890.0),\n",
    "    'GF_HYB_NAPH': (830.0, 853.0),\n",
    "}\n",
    "\n",
    "\n",
    "# wrap it\n",
    "memo_spyro = SpyroMemo(total_spyro_yield_for_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26096c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML/GP window: 2024-07-05 09:00:00 → 2025-01-01 09:00:00\n",
      "Rows in lookback window: 360 (MIN_TR_ROWS = 180 )\n"
     ]
    }
   ],
   "source": [
    "first_eval_day = pd.Timestamp('2025-01-01')\n",
    "train_end = (X_12h.index[(X_12h.index >= first_eval_day) &\n",
    "                         (X_12h.index < first_eval_day + pd.Timedelta(days=1))][-1]\n",
    "             - pd.Timedelta(hours=12))\n",
    "train_start = train_end - LOOKBACK_6M\n",
    "print(\"ML/GP window:\", train_start, \"→\", train_end)\n",
    "\n",
    "window_rows = ((X_12h.index >= train_start) & (X_12h.index < train_end)).sum()\n",
    "print(\"Rows in lookback window:\", window_rows, \"(MIN_TR_ROWS =\", MIN_TR_ROWS, \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3272671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethylene_prod_t+1',\n",
       " 'Propylene_prod_t+1',\n",
       " 'MixedC4_prod_t+1',\n",
       " 'RPG_prod_t+1',\n",
       " 'Ethane_prod_t+1',\n",
       " 'Propane_prod_t+1',\n",
       " 'Hydrogen_prod_t+1',\n",
       " 'Tail_Gas_prod_t+1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a008f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Active RCOT knobs (name, rcot, flow_tph):\n",
      "  RCOT_chamber2              835.01 °C   flow= 55.971 t/h\n",
      "  RCOT_chamber3              835.00 °C   flow= 55.597 t/h\n",
      "  RCOT_gas_chamber5          880.02 °C   flow= 52.721 t/h\n",
      "  RCOT_naphtha_chamber6      839.99 °C   flow= 57.526 t/h\n",
      "\n",
      "=== MULTI-KNOB RESULT ===\n",
      "Status: ok\n",
      "ΔMargin $/h: 572.99\n",
      "RCOT* (per chamber):\n",
      "  RCOT_chamber2              835.01 →  840.01  (Δ +5.00)\n",
      "  RCOT_chamber3              835.00 →  840.00  (Δ +5.00)\n",
      "  RCOT_gas_chamber5          880.02 →  885.02  (Δ +5.00)\n",
      "  RCOT_naphtha_chamber6      839.99 →  844.99  (Δ +5.00)\n",
      "\n",
      "--- Expected Δ by chamber (corrected; sums to total) ---\n",
      "         d_Ethylene_tph  d_Propylene_tph  d_MixedC4_tph  d_RPG_tph  d_TailGas_tph  d_Hydrogen_tph  d_margin_per_h\n",
      "chamber                                                                                                          \n",
      "2                0.4143          -0.0324         0.0009    -0.4750         0.2087          0.0151        162.2037\n",
      "3                0.4115          -0.0321         0.0009    -0.4719         0.2073          0.0150        161.1339\n",
      "5                0.3897          -0.1250         0.1233     0.0701         0.2313          0.0453        156.6951\n",
      "6                0.3341          -0.1162        -0.0278    -0.3145         0.2002          0.0133         92.9607\n",
      "\n",
      "--- Physics Δ by chamber (SRTO legs) ---\n",
      "         d_Ethylene_tph  d_Propylene_tph  d_MixedC4_tph  d_RPG_tph  d_Tail_Gas_tph  d_Hydrogen_tph\n",
      "chamber                                                                                           \n",
      "2                0.4143          -0.0324         0.0009    -0.4750          0.2087          0.0151\n",
      "3                0.4115          -0.0321         0.0009    -0.4719          0.2073          0.0150\n",
      "5                0.3897          -0.1250         0.1233     0.0701          0.2313          0.0453\n",
      "6                0.3341          -0.1162        -0.0278    -0.3145          0.2002          0.0133\n",
      "\n",
      "=== PRICE SNAPSHOT @ 2025-01-01 09:00:00 ===\n",
      "{'Ethylene': 826.9195557, 'Propylene': 805.7999878, 'Mixed C4': 879.2357788, 'RPG': 687.1991577, 'Hydrogen': 2030.930786, 'Tail Gas': 730.1395264, 'Fuel Gas': 621.9199829, 'PN': 676.8546753, 'Gas Feed': 0.0, 'LPG': 567.9401855, 'MX Offgas': 683.4105835}\n",
      "\n",
      "=== BEFORE vs AFTER (per product) ===\n",
      "  product  qty_before  qty_after     price  rev_before  rev_after  rev_delta\n",
      " Ethylene      64.632     66.182   826.920  53,445.614 54,727.089  1,281.474\n",
      " Hydrogen       1.680      1.769 2,030.931   3,411.929  3,592.006    180.077\n",
      " Mixed C4      23.833     23.931   879.236  20,955.185 21,040.694     85.509\n",
      "Propylene      35.821     35.515   805.800  28,864.537 28,618.241   -246.295\n",
      "      RPG      53.810     52.619   687.199  36,978.406 36,159.761   -818.645\n",
      " Tail Gas      31.522     32.369   730.140  23,015.330 23,634.150    618.819\n",
      "\n",
      "=== SUMMARY ($/h) ===\n",
      "Revenue      : 166,671.00  →  167,771.94   (Δ +1,100.94)\n",
      "Feed cost    : 130,560.02 →  130,560.02  (Δ +0.00)\n",
      "Recycle cred.: 13,876.62 →  13,426.98  (Δ -449.64)\n",
      "ΔFG (tph)    : -0.241236 → -0.115324 (Δ +0.125913) × Fuel Gas=621.92 → FG cost Δ: +78.31\n",
      "MARGIN       : 50,137.63 → 50,710.63 (Δ +572.99)\n",
      "[APPLIED next_stamp] 2025-01-01 09:00:00 -> 2025-01-01 21:00:00\n",
      "  rcots@ts   : {'RCOT_chamber2': 835.0071319145932, 'RCOT_chamber3': 835.0042896947247, 'RCOT_gas_chamber5': 880.0180056200428, 'RCOT_naphtha_chamber6': 839.9901574771825}\n",
      "  rcots@next : {'RCOT_chamber2': 840.0071319074984, 'RCOT_chamber3': 840.0042896876739, 'RCOT_gas_chamber5': 885.0180056112245, 'RCOT_naphtha_chamber6': 844.990157463037}\n",
      "\n",
      "Active RCOT knobs (name, rcot, flow_tph):\n",
      "  RCOT_chamber2              840.01 °C   flow= 56.409 t/h\n",
      "  RCOT_chamber3              840.00 °C   flow= 56.152 t/h\n",
      "  RCOT_gas_chamber5          885.02 °C   flow= 53.053 t/h\n",
      "  RCOT_naphtha_chamber6      844.99 °C   flow= 57.462 t/h\n",
      "\n",
      "=== MULTI-KNOB RESULT ===\n",
      "Status: ok\n",
      "ΔMargin $/h: 489.01\n",
      "RCOT* (per chamber):\n",
      "  RCOT_chamber2              840.01 →  845.01  (Δ +5.00)\n",
      "  RCOT_chamber3              840.00 →  845.00  (Δ +5.00)\n",
      "  RCOT_gas_chamber5          885.02 →  890.00  (Δ +4.98)\n",
      "  RCOT_naphtha_chamber6      844.99 →  849.99  (Δ +5.00)\n",
      "\n",
      "--- Expected Δ by chamber (corrected; sums to total) ---\n",
      "         d_Ethylene_tph  d_Propylene_tph  d_MixedC4_tph  d_RPG_tph  d_TailGas_tph  d_Hydrogen_tph  d_margin_per_h\n",
      "chamber                                                                                                          \n",
      "2                0.3959          -0.0604        -0.0118    -0.4315         0.2044          0.0149        139.0531\n",
      "3                0.3941          -0.0601        -0.0117    -0.4296         0.2035          0.0148        138.4322\n",
      "5                0.3289          -0.1189         0.1247     0.0730         0.2246          0.0441        138.7323\n",
      "6                0.3161          -0.1376        -0.0358    -0.2791         0.1947          0.0131         72.7882\n",
      "\n",
      "--- Physics Δ by chamber (SRTO legs) ---\n",
      "         d_Ethylene_tph  d_Propylene_tph  d_MixedC4_tph  d_RPG_tph  d_Tail_Gas_tph  d_Hydrogen_tph\n",
      "chamber                                                                                           \n",
      "2                0.3959          -0.0604        -0.0118    -0.4315          0.2044          0.0149\n",
      "3                0.3941          -0.0601        -0.0117    -0.4296          0.2035          0.0148\n",
      "5                0.3289          -0.1189         0.1247     0.0730          0.2246          0.0441\n",
      "6                0.3161          -0.1376        -0.0358    -0.2791          0.1947          0.0131\n",
      "\n",
      "=== PRICE SNAPSHOT @ 2025-01-01 21:00:00 ===\n",
      "{'Ethylene': 826.9195557, 'Propylene': 805.7999878, 'Mixed C4': 879.2357788, 'RPG': 687.1991577, 'Hydrogen': 2030.930786, 'Tail Gas': 730.1395264, 'Fuel Gas': 621.9199829, 'PN': 676.8546753, 'Gas Feed': 0.0, 'LPG': 567.9401855, 'MX Offgas': 683.4105835}\n",
      "\n",
      "=== BEFORE vs AFTER (per product) ===\n",
      "  product  qty_before  qty_after     price  rev_before  rev_after  rev_delta\n",
      " Ethylene      64.882     66.317   826.920  53,652.550 54,839.099  1,186.549\n",
      " Hydrogen       1.667      1.753 2,030.931   3,384.786  3,561.229    176.443\n",
      " Mixed C4      23.538     23.604   879.236  20,695.803 20,753.230     57.426\n",
      "Propylene      35.176     34.799   805.800  28,344.772 28,040.938   -303.835\n",
      "      RPG      54.115     53.048   687.199  37,187.778 36,454.418   -733.360\n",
      " Tail Gas      31.726     32.553   730.140  23,164.347 23,768.220    603.873\n",
      "\n",
      "=== SUMMARY ($/h) ===\n",
      "Revenue      : 166,430.04  →  167,417.13   (Δ +987.10)\n",
      "Feed cost    : 130,899.51 →  130,899.51  (Δ +0.00)\n",
      "Recycle cred.: 13,942.06 →  13,515.37  (Δ -426.70)\n",
      "ΔFG (tph)    : -0.383706 → -0.268907 (Δ +0.114799) × Fuel Gas=621.92 → FG cost Δ: +71.40\n",
      "MARGIN       : 49,711.22 → 50,200.23 (Δ +489.01)\n",
      "[APPLIED next_stamp] 2025-01-01 21:00:00 -> 2025-01-02 09:00:00\n",
      "  rcots@ts   : {'RCOT_chamber2': 840.0071319074984, 'RCOT_chamber3': 840.0042896876739, 'RCOT_gas_chamber5': 885.0180056112245, 'RCOT_naphtha_chamber6': 844.990157463037}\n",
      "  rcots@next : {'RCOT_chamber2': 845.0071318994375, 'RCOT_chamber3': 845.0042896796516, 'RCOT_gas_chamber5': 889.9999999899625, 'RCOT_naphtha_chamber6': 849.990157463037}\n",
      "\n",
      "Active RCOT knobs (name, rcot, flow_tph):\n",
      "  RCOT_chamber2              845.01 °C   flow= 56.091 t/h\n",
      "  RCOT_chamber3              845.00 °C   flow= 56.136 t/h\n",
      "  RCOT_gas_chamber5          890.00 °C   flow= 52.687 t/h\n",
      "  RCOT_naphtha_chamber6      849.99 °C   flow= 57.335 t/h\n",
      "\n",
      "=== MULTI-KNOB RESULT ===\n",
      "Status: ok\n",
      "ΔMargin $/h: 251.46\n",
      "RCOT* (per chamber):\n",
      "  RCOT_chamber2              845.01 →  850.01  (Δ +5.00)\n",
      "  RCOT_chamber3              845.00 →  850.00  (Δ +5.00)\n",
      "  RCOT_gas_chamber5          890.00 →  890.00  (Δ -0.00)\n",
      "  RCOT_naphtha_chamber6      849.99 →  853.00  (Δ +3.01)\n",
      "\n",
      "--- Expected Δ by chamber (corrected; sums to total) ---\n",
      "         d_Ethylene_tph  d_Propylene_tph  d_MixedC4_tph  d_RPG_tph  d_TailGas_tph  d_Hydrogen_tph  d_margin_per_h\n",
      "chamber                                                                                                          \n",
      "2                0.3678          -0.0864        -0.0275    -0.3769         0.1943          0.0144        109.8455\n",
      "3                0.3681          -0.0864        -0.0275    -0.3773         0.1945          0.0144        109.9457\n",
      "5               -0.0000           0.0000        -0.0000    -0.0000        -0.0000         -0.0000         -0.0000\n",
      "6                0.1797          -0.0923        -0.0274    -0.1484         0.1127          0.0078         31.6661\n",
      "\n",
      "--- Physics Δ by chamber (SRTO legs) ---\n",
      "         d_Ethylene_tph  d_Propylene_tph  d_MixedC4_tph  d_RPG_tph  d_Tail_Gas_tph  d_Hydrogen_tph\n",
      "chamber                                                                                           \n",
      "2                0.3678          -0.0864        -0.0275    -0.3769          0.1943          0.0144\n",
      "3                0.3681          -0.0864        -0.0275    -0.3773          0.1945          0.0144\n",
      "5               -0.0000           0.0000        -0.0000    -0.0000         -0.0000         -0.0000\n",
      "6                0.1797          -0.0923        -0.0274    -0.1484          0.1127          0.0078\n",
      "\n",
      "=== PRICE SNAPSHOT @ 2025-01-02 09:00:00 ===\n",
      "{'Ethylene': 826.9195557, 'Propylene': 805.7999878, 'Mixed C4': 879.2357788, 'RPG': 687.1991577, 'Hydrogen': 2030.930786, 'Tail Gas': 730.1395264, 'Fuel Gas': 621.9199829, 'PN': 676.8546753, 'Gas Feed': 0.0, 'LPG': 567.9401855, 'MX Offgas': 683.4105835}\n",
      "\n",
      "=== BEFORE vs AFTER (per product) ===\n",
      "  product  qty_before  qty_after     price  rev_before  rev_after  rev_delta\n",
      " Ethylene      65.442     66.358   826.920  54,115.464 54,872.600    757.137\n",
      " Hydrogen       1.674      1.710 2,030.931   3,399.092  3,473.450     74.358\n",
      " Mixed C4      23.740     23.658   879.236  20,872.940 20,800.583    -72.357\n",
      "Propylene      35.434     35.169   805.800  28,552.640 28,339.026   -213.615\n",
      "      RPG      54.817     53.915   687.199  37,670.346 37,050.091   -620.255\n",
      " Tail Gas      31.964     32.465   730.140  23,338.063 23,704.283    366.220\n",
      "\n",
      "=== SUMMARY ($/h) ===\n",
      "Revenue      : 167,948.54  →  168,240.03   (Δ +291.49)\n",
      "Feed cost    : 130,926.30 →  130,926.30  (Δ +0.00)\n",
      "Recycle cred.: 13,847.74 →  13,852.06  (Δ +4.32)\n",
      "ΔFG (tph)    : -0.328148 → -0.256836 (Δ +0.071313) × Fuel Gas=621.92 → FG cost Δ: +44.35\n",
      "MARGIN       : 51,074.06 → 51,325.52 (Δ +251.46)\n",
      "[APPLIED next_stamp] 2025-01-02 09:00:00 -> 2025-01-02 21:00:00\n",
      "  rcots@ts   : {'RCOT_chamber2': 845.0071318994375, 'RCOT_chamber3': 845.0042896796516, 'RCOT_gas_chamber5': 889.9999999899625, 'RCOT_naphtha_chamber6': 849.990157463037}\n",
      "  rcots@next : {'RCOT_chamber2': 850.0071318285391, 'RCOT_chamber3': 850.0042896087043, 'RCOT_gas_chamber5': 889.9999999118652, 'RCOT_naphtha_chamber6': 852.9999998581543}\n",
      "\n",
      "Active RCOT knobs (name, rcot, flow_tph):\n",
      "  RCOT_chamber2              850.01 °C   flow= 58.267 t/h\n",
      "  RCOT_chamber3              850.00 °C   flow= 58.411 t/h\n",
      "  RCOT_gas_chamber5          890.00 °C   flow= 51.343 t/h\n",
      "  RCOT_naphtha_chamber6      853.00 °C   flow= 57.030 t/h\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m TARGET_COLS_ML = TARGET_COLS\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Example daily run for the whole horizon (or pass a shorter end date)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mrun_production\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_12h\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_12h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_12h\u001b[49m\u001b[43m=\u001b[49m\u001b[43mY_12h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmerged_lims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerged_lims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprices_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprices_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_spyro_yield_for_now\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemo_spyro\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2025-01-01\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2025-05-19\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclosed_loop\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclosed_loop_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapply_timing\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnext_stamp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# or 'next_stamp'\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhold_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhold_until_next\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# step & hold\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mml_train_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msimulated\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# train ML on historical windows (fast/stable)\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgp_train_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msimulated\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# train GP on historical windows\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_tag\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_sim\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# keep caches separate\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 960\u001b[39m, in \u001b[36mrun_production\u001b[39m\u001b[34m(X_12h, Y_12h, merged_lims, pipeline, prices_df, total_spyro_yield_for_now, start, end, mode, closed_loop_opts)\u001b[39m\n\u001b[32m    941\u001b[39m pd.DataFrame(active, columns=[\u001b[33m'\u001b[39m\u001b[33mknob\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mrcot_C\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mflow_tph\u001b[39m\u001b[33m'\u001b[39m]).assign(timestamp=ts)\\\n\u001b[32m    942\u001b[39m     .to_csv(AK_DIR / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactive_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mts\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m%Y%m%d_%H%M\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# optimize multi-knob (tuned α)\u001b[39;00m\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# res = opt.optimize_rcot_for_ts_multi(\u001b[39;00m\n\u001b[32m    946\u001b[39m \u001b[38;5;66;03m#     ts=ts, row0=row_current,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    957\u001b[39m \u001b[38;5;66;03m#     bounds_by_knob=bounds_by_knob           # ← NEW\u001b[39;00m\n\u001b[32m    958\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m res = \u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize_rcot_for_ts_multi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_current\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgps_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols_gp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_cols_gp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_spyro_yield_for_now\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_spyro_yield_for_now\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspyro_ctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprice_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mper_hour\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnaph_bounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnaph_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgas_bounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgas_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_delta_C\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# ← your ±5 °C window\u001b[39;49;00m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_recycle_fixed_point\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecycle_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmargin_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexcel_delta\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfg_constants\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfg_consts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha_overrides\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# not used in anchored mode\u001b[39;49;00m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_de\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_slsqp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbounds_by_knob\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds_by_knob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# NEW for anchored-mode\u001b[39;49;00m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43manchored_from_ml\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_lims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerged_lims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_cached\u001b[49m\u001b[43m=\u001b[49m\u001b[43mml_cached\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha_default_for_anchor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# pure SRTO slopes\u001b[39;49;00m\n\u001b[32m    978\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    981\u001b[39m row_opt = res[\u001b[33m'\u001b[39m\u001b[33mrow_opt\u001b[39m\u001b[33m'\u001b[39m]; y_opt = res[\u001b[33m'\u001b[39m\u001b[33myields_opt\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    982\u001b[39m m_base  = res[\u001b[33m'\u001b[39m\u001b[33mmargin_current_per_h\u001b[39m\u001b[33m'\u001b[39m]; m_opt = res[\u001b[33m'\u001b[39m\u001b[33mmargin_opt_per_h\u001b[39m\u001b[33m'\u001b[39m]; d_m = res[\u001b[33m'\u001b[39m\u001b[33mimprovement_per_h\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\optimizer.py:1551\u001b[39m, in \u001b[36moptimize_rcot_for_ts_multi\u001b[39m\u001b[34m(ts, row0, gps, feature_cols_gp, total_spyro_yield_for_now, spyro_ctx, price_provider, objective, naph_bounds, gas_bounds, trust_delta_C, use_recycle_fixed_point, recycle_fn, recycle_iters, recycle_damping, recycle_tol, alpha_overrides, margin_mode, fg_constants, util_models, util_feature_cols, enable_de, de_maxiter, de_popsize, enable_slsqp, slsqp_maxiter, delta_fg_fn, delta_fg_kwargs, bounds_by_knob, anchored_from_ml, gp, pipeline, merged_lims, ml_cached, alpha_default_for_anchor)\u001b[39m\n\u001b[32m   1548\u001b[39m         x_best, out_best = res.x, eval_candidate(res.x)\n\u001b[32m   1550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m enable_de \u001b[38;5;129;01mand\u001b[39;00m _HAS_DE:\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m     res_d = \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbest1bin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mde_maxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mpopsize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mde_popsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolish\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1554\u001b[39m     x_de, out_de = res_d.x, eval_candidate(res_d.x)\n\u001b[32m   1555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m -neg_obj(x_de) > -neg_obj(x_best):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\spyro\\Lib\\site-packages\\scipy\\_lib\\_util.py:352\u001b[39m, in \u001b[36m_transition_to_rng.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    345\u001b[39m     message = (\n\u001b[32m    346\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe NumPy global RNG was seeded by calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    347\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`np.random.seed`. Beginning in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    348\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfunction will no longer use the global RNG.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    349\u001b[39m     ) + cmn_msg\n\u001b[32m    350\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\spyro\\Lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:502\u001b[39m, in \u001b[36mdifferential_evolution\u001b[39m\u001b[34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, rng, callback, disp, polish, init, atol, updating, workers, constraints, x0, integrality, vectorized)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args=args,\n\u001b[32m    488\u001b[39m                                  strategy=strategy,\n\u001b[32m    489\u001b[39m                                  maxiter=maxiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    500\u001b[39m                                  integrality=integrality,\n\u001b[32m    501\u001b[39m                                  vectorized=vectorized) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m     ret = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\spyro\\Lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:1177\u001b[39m, in \u001b[36mDifferentialEvolutionSolver.solve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1172\u001b[39m     \u001b[38;5;28mself\u001b[39m.feasible, \u001b[38;5;28mself\u001b[39m.constraint_violation = (\n\u001b[32m   1173\u001b[39m         \u001b[38;5;28mself\u001b[39m._calculate_population_feasibilities(\u001b[38;5;28mself\u001b[39m.population))\n\u001b[32m   1175\u001b[39m     \u001b[38;5;66;03m# only work out population energies for feasible solutions\u001b[39;00m\n\u001b[32m   1176\u001b[39m     \u001b[38;5;28mself\u001b[39m.population_energies[\u001b[38;5;28mself\u001b[39m.feasible] = (\n\u001b[32m-> \u001b[39m\u001b[32m1177\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_population_energies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeasible\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1180\u001b[39m     \u001b[38;5;28mself\u001b[39m._promote_lowest_energy()\n\u001b[32m   1182\u001b[39m \u001b[38;5;66;03m# do the optimization.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\spyro\\Lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:1338\u001b[39m, in \u001b[36mDifferentialEvolutionSolver._calculate_population_energies\u001b[39m\u001b[34m(self, population)\u001b[39m\n\u001b[32m   1336\u001b[39m parameters_pop = \u001b[38;5;28mself\u001b[39m._scale_parameters(population)\n\u001b[32m   1337\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m     calc_energies = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mapwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters_pop\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1341\u001b[39m     calc_energies = np.squeeze(calc_energies)\n\u001b[32m   1342\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1343\u001b[39m     \u001b[38;5;66;03m# wrong number of arguments for _mapwrapper\u001b[39;00m\n\u001b[32m   1344\u001b[39m     \u001b[38;5;66;03m# or wrong length returned from the mapper\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\spyro\\Lib\\site-packages\\scipy\\_lib\\_util.py:575\u001b[39m, in \u001b[36m_FunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\optimizer.py:1551\u001b[39m, in \u001b[36moptimize_rcot_for_ts_multi.<locals>.<lambda>\u001b[39m\u001b[34m(z)\u001b[39m\n\u001b[32m   1548\u001b[39m         x_best, out_best = res.x, eval_candidate(res.x)\n\u001b[32m   1550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m enable_de \u001b[38;5;129;01mand\u001b[39;00m _HAS_DE:\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m     res_d = differential_evolution(\u001b[38;5;28;01mlambda\u001b[39;00m z: \u001b[43mneg_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, bounds=\u001b[38;5;28mtuple\u001b[39m(bounds),\n\u001b[32m   1552\u001b[39m                                    strategy=\u001b[33m'\u001b[39m\u001b[33mbest1bin\u001b[39m\u001b[33m'\u001b[39m, maxiter=de_maxiter,\n\u001b[32m   1553\u001b[39m                                    popsize=de_popsize, tol=\u001b[32m0.01\u001b[39m, seed=\u001b[32m0\u001b[39m, polish=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1554\u001b[39m     x_de, out_de = res_d.x, eval_candidate(res_d.x)\n\u001b[32m   1555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m -neg_obj(x_de) > -neg_obj(x_best):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\optimizer.py:1531\u001b[39m, in \u001b[36moptimize_rcot_for_ts_multi.<locals>.neg_obj\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1530\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mneg_obj\u001b[39m(x):\n\u001b[32m-> \u001b[39m\u001b[32m1531\u001b[39m     m_h, m_t, *_ = \u001b[43meval_candidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m - (m_t \u001b[38;5;28;01mif\u001b[39;00m objective == \u001b[33m'\u001b[39m\u001b[33mper_ton_fresh\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m m_h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\optimizer.py:1524\u001b[39m, in \u001b[36moptimize_rcot_for_ts_multi.<locals>.eval_candidate\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_candidate\u001b[39m(x):\n\u001b[32m   1523\u001b[39m     r_c = _apply(x)\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m     y_c = \u001b[43m_corrected\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1525\u001b[39m     m_h = margin_fn(ts, r_c, y_c)\n\u001b[32m   1526\u001b[39m     fresh = _fresh_basis_tph(r_c, y_c)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\optimizer.py:1500\u001b[39m, in \u001b[36moptimize_rcot_for_ts_multi.<locals>._corrected\u001b[39m\u001b[34m(r_like)\u001b[39m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_corrected\u001b[39m(r_like):\n\u001b[32m   1499\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m anchored_from_ml:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43manchored_expected_for_row\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrow_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_cand\u001b[49m\u001b[43m=\u001b[49m\u001b[43mr_like\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_lims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmerged_lims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m            \u001b[49m\u001b[43mml_cached\u001b[49m\u001b[43m=\u001b[49m\u001b[43mml_cached\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m            \u001b[49m\u001b[43malpha_default\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha_default_for_anchor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 0.0 → pure SRTO slopes\u001b[39;49;00m\n\u001b[32m   1505\u001b[39m \u001b[43m            \u001b[49m\u001b[43malpha_overrides\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   1506\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1507\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1508\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m corrected_yields_for_row(\n\u001b[32m   1509\u001b[39m             r_like, gps, feature_cols_gp, total_spyro_yield_for_now, spyro_ctx, alpha_overrides\n\u001b[32m   1510\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\optimizer.py:1367\u001b[39m, in \u001b[36manchored_expected_for_row\u001b[39m\u001b[34m(row_base, row_cand, gp, pipeline, merged_lims, ml_cached, alpha_default, alpha_overrides)\u001b[39m\n\u001b[32m   1364\u001b[39m comp_row = gp._comp_row_for_ts(merged_lims, ts) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(gp, \u001b[33m'\u001b[39m\u001b[33m_comp_row_for_ts\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1366\u001b[39m spot0 = pipeline.predict_spot_plant(row_base, comp_row, feed_thr=\u001b[32m0.1\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mtotals_tph\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1367\u001b[39m spot1 = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_spot_plant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_cand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomp_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_thr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtotals_tph\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m   1369\u001b[39m \u001b[38;5;66;03m# ML anchor at rc0\u001b[39;00m\n\u001b[32m   1370\u001b[39m ml_point = ml_cached.predict_row(row_base) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ml_cached, \u001b[33m'\u001b[39m\u001b[33mpredict_row\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\srto_pipeline.py:949\u001b[39m, in \u001b[36mSRTOPipeline.predict_spot_plant\u001b[39m\u001b[34m(self, X_row, composition_row, feed_thr, rcot_bounds)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m leg \u001b[38;5;129;01min\u001b[39;00m legs:\n\u001b[32m    948\u001b[39m     rc = \u001b[38;5;28mself\u001b[39m._sanitize_rcot(leg[\u001b[33m'\u001b[39m\u001b[33mrcot\u001b[39m\u001b[33m'\u001b[39m], bounds=rcot_bounds)\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m     spot = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_spot_leg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomposition_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgeometry\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m     \u001b[38;5;66;03m# status per leg\u001b[39;00m\n\u001b[32m    952\u001b[39m     iret = \u001b[38;5;28mfloat\u001b[39m(spot.get(\u001b[33m'\u001b[39m\u001b[33mIRET\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\srto_pipeline.py:898\u001b[39m, in \u001b[36mSRTOPipeline._spot_leg\u001b[39m\u001b[34m(self, composition_row, geometry_key, rcot)\u001b[39m\n\u001b[32m    896\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run a single leg by geometry key, resolving to the actual .SPY7 path.\"\"\"\u001b[39;00m\n\u001b[32m    897\u001b[39m gpath = \u001b[38;5;28mself\u001b[39m._find_geometry_path(geometry_key)\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_spot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomposition_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomposition_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeometry_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrcot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrcot\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\srto_pipeline.py:638\u001b[39m, in \u001b[36mSRTOPipeline.predict_spot\u001b[39m\u001b[34m(self, composition_row, geometry_name_or_path, rcot)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28mself\u001b[39m.spyin_builder.set_rcot(spyin, rcot)\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m# Run sim\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msrto_interface\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeom_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspyin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m out.update({\n\u001b[32m    640\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgeometry\u001b[39m\u001b[33m'\u001b[39m: geom_name,\n\u001b[32m    641\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeed_type\u001b[39m\u001b[33m'\u001b[39m: feed_type,\n\u001b[32m    642\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mRCOT\u001b[39m\u001b[33m'\u001b[39m: rcot,\n\u001b[32m    643\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m: composition_row.get(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m, pd.NaT)\n\u001b[32m    644\u001b[39m })\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\Downloads\\EFOM\\src\\srto_pipeline.py:179\u001b[39m, in \u001b[36mSRTOInterface.run_simulation\u001b[39m\u001b[34m(self, geometry_path, spyin_buffer, buffers)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mself\u001b[39m.dll.SRTO_START(ct.byref(buffers[\u001b[33m'\u001b[39m\u001b[33mNSERVERS\u001b[39m\u001b[33m'\u001b[39m]), ct.byref(buffers[\u001b[33m'\u001b[39m\u001b[33mIRET\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUASSPY7\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfgeom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mct\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int64\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspyin_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDSPYIN\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSPYOUT\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDSPYOUT\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mct\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffers\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mIRET\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# Extract results\u001b[39;00m\n\u001b[32m    187\u001b[39m spyout = buffers[\u001b[33m'\u001b[39m\u001b[33mSPYOUT\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "TARGET_COLS_ML = TARGET_COLS\n",
    "\n",
    "# Example daily run for the whole horizon (or pass a shorter end date)\n",
    "run_production(\n",
    "    X_12h=X_12h, Y_12h=Y_12h,\n",
    "    merged_lims=merged_lims, pipeline=pipeline,\n",
    "    prices_df=prices_df,\n",
    "    total_spyro_yield_for_now=memo_spyro,\n",
    "    start=pd.Timestamp('2025-01-01'), end=pd.Timestamp('2025-05-19'),\n",
    "    mode='closed_loop',\n",
    "    closed_loop_opts=dict(\n",
    "        apply_timing='next_stamp',          # or 'next_stamp'\n",
    "        hold_policy='hold_until_next',    # step & hold\n",
    "        ml_train_mode='simulated',       # train ML on historical windows (fast/stable)\n",
    "        gp_train_mode='simulated',       # train GP on historical windows\n",
    "        cache_tag='_sim'                  # keep caches separate\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78970c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "From your run: \n",
    "• ΔFG (burner) = +0.125913 t/h • fuel_gas_heat_content_kcal_per_ton = 15_294_088 kcal/t (= 15.294 Gcal/t)\n",
    "Your utility shows 427.882 MMkcal/h on 2025‑01‑01. So the modeled Δ is ~0.45% of the meter (1.926 / 427.882 ≈ 0.0045). \n",
    "That’s a perfectly reasonable order of magnitude for +5 °C on a handful of RCOT knobs with ~220 t/h fresh feed.\n",
    "\n",
    "\n",
    "normalize the meter \n",
    " (1.926 / 427.882 ≈ 0.0045, or 0.45%)\n",
    "and that is \n",
    "delta Q = how much stuff flows (m mix) * Cp,mix (how hard it is to heat) * delta T (how much temperature you add) / eta heater (losses up the stack)\n",
    "\n",
    "Plugging in simple, round numbers\n",
    "Use a middle-of-the-road case:\n",
    "\n",
    "𝑚 mix=300 t/h=300,000 kg/h\n",
    "𝐶𝑝=5 kJ/kg-K\n",
    "=5 kJ/kg-K\n",
    "Δ𝑇=5 K\n",
    "𝜂=0.90\n",
    "Compute the heat per hour:\n",
    "300,000 kg/h×5 kJ/kg-K×5 K=7,500,000 kJ/h\n",
    "=7,500,000 kJ/h\n",
    "\n",
    "Divide by efficiency: \n",
    "7,500,000/0.90\n",
    "=8,333,333 kJ/h\n",
    "7,500,000/0.90=8,333,333 kJ/h\n",
    "Convert to Gcal/h (1 Gcal = 4,184,000 kJ):\n",
    "8,333,333/4,184,000\n",
    "= 1.99 Gcal/h\n",
    "8,333,333/4,184,000=1.99 Gcal/h\n",
    "\n",
    "So a +5 °C step costs ≈2.0 Gcal/h in this “middle” case.\n",
    "What range should you expect?\n",
    "If you vary the inputs within realistic bounds:\n",
    "\n",
    "𝑚 mix=300–320 t/h\n",
    "𝐶𝑝=4–6 kJ/kg-K\n",
    "𝜂=0.85–0.92\n",
    "Δ𝑇=5 °C\n",
    "\n",
    "=4–6 kJ/kg-K\n",
    "\n",
    "𝜂=0.85–0.92\n",
    "Δ𝑇=5 °C\n",
    "\n",
    "𝑇=5 °C\n",
    "ΔT=5 °C\n",
    "\n",
    "You get ~1.6 to 2.6 Gcal/h.\n",
    "Your modeled 1.926 Gcal/h lands neatly inside that band → it’s physically reasonable.\n",
    "Converting that heat to extra fuel-gas mass\n",
    "You already did this correctly: divide by the gas HHV.\n",
    "HHV ≈ 15.294 Gcal/t\n",
    "Extra heat ≈ 1.926 Gcal/h\n",
    "Extra FG ≈ 1.926/15.294=0.126\n",
    " t/h\n",
    "1.926/15.294=0.126 t/h\n",
    "\n",
    "Two handy “rules of thumb”\n",
    "\n",
    "Per degree, per flow:\n",
    "With 𝐶𝑝≈5 kJ/kg-K and 𝜂≈0.90, each 1 °C needs about\n",
    "0.00133 Gcal/h for every 1 t/h flowing through the coils.\n",
    "So for 300 t/h, +5 °C ≈ 300×5×0.00133\n",
    "≈2.0 Gcal/h\n",
    "300×5×0.00133≈2.0 Gcal/h.\n",
    "\n",
    "Fuel mass from heat:\n",
    "Extra FG (t/h) ≈ Δ𝑄\n",
    "ΔQ (Gcal/h) ÷ HHV (Gcal/t).\n",
    "With HHV = 15.294, 2.0 Gcal/h → ~0.13 t/h.\n",
    "\n",
    "Tiny nuance (don’t overthink it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749514d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537febc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb6ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
